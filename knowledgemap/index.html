<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 100vh;
                 background-color: #000000;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             

             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"color": "#C41E3A", "fixed": false, "font": {"color": "white"}, "id": "Math", "label": "Math", "mass": 8.37, "shape": "dot", "size": 28.930952282978865, "title": ""}, {"color": "#FF6F20", "fixed": false, "font": {"color": "white"}, "id": "Statistics", "label": "Statistics", "mass": 4.82, "shape": "dot", "size": 21.95449840010015, "title": ""}, {"color": "#c41e3a", "fixed": false, "font": {"color": "white"}, "id": "Information Theory", "label": "Information Theory", "mass": 1.29, "shape": "dot", "size": 11.357816691600547, "title": ""}, {"color": "#c41e3a", "fixed": false, "font": {"color": "white"}, "id": "Linear Algebra", "label": "Linear Algebra", "mass": 2.0000000000000004, "shape": "dot", "size": 14.142135623730951, "title": ""}, {"color": "#c41e3a", "fixed": false, "font": {"color": "white"}, "id": "Calculus", "label": "Calculus", "mass": 2.5, "shape": "dot", "size": 15.811388300841896, "title": ""}, {"color": "#ff6f20", "fixed": false, "font": {"color": "white"}, "id": "Optimization", "label": "Optimization", "mass": 2.3200000000000003, "shape": "dot", "size": 15.231546211727817, "title": ""}, {"color": {"background": "#ff6f20", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Momentum,-RMSProp,-Adam/", "id": "Momentum, RMSProp, Adam", "label": "Momentum, RMSProp, Adam", "mass": 1.0, "shape": "dot", "size": 10.0, "title": "# Momentum, RMSProp, Adam\n\nNotes from \"A visual explanation\"\n\nMomentum in Physics - F = ma, a force will cause a constant change in velocity.\nSame as momentum in ML - momentum = velocity, \nforces = decay (friction), and the additional gradient\nderivative = applying a force for one time frame, leading to an acceleration (change in velocity)\nmomentum helps with plateaus and local minima\n\n\nAdaGrad - history of squared gradients for a direction accumulate, updates in that direction are divided by this\nencourages exploration in directions where not many changes have happened\nescapes saddle points better - regular GD optimizes steeper features first\nslow b/c squared gradient accumuates\n\n\nRMSProp - squared gradients decay, squared gradients have momentum\n\nAdam - gradients have momentum, so do squared gradients.\nmomentum allows for escaping local minima\nsum of squares = explore new directions\n\n\n\nNotes from Andrew NG:\nMomentum cancels oscillations\nCorrections are usually applied to Adam so things get rolling earlier\nLast Reviewed: 11/9/24\n\n\n\n\n\n"}, {"color": {"background": "#c41e3a", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Gradients/", "id": "Gradients", "label": "Gradients", "mass": 2.0000000000000004, "shape": "dot", "size": 14.142135623730951, "title": "# Gradients\n\nGradient indicates direction of highest increase\nGradient specifies linearization (plane) of the function up to an offset (derivative gets rid of +C)\nGradient direction specifies plane orientation\nGradient magnitude specifies plane slope\nPlane tells you all directional derivatives\nLast Reviewed: 10/27/24\n"}, {"color": {"background": "#c41e3a", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Chain-Rule/", "id": "Chain Rule", "label": "Chain Rule", "mass": 1.0, "shape": "dot", "size": 10.0, "title": "# Chain Rule\n\nReference Page: #1\nUnivariate Chain Rule - \u0027speeding up\u0027 interperation.\n\u0027boosting\u0027 at a point\n\nAll derivatives are evaluated at the same point, just in different input domains\n\nMultivariate chain rule, dx,dy can be separated due to linearization.\nIncreases accumulate across dx, and dy.\n\nextending to multi-in, multi-out\nviewing things in terms of unit changes after linearization.\n\nKey Idea: we can think of moving dx in x, and then moving dy in y,\nand seeing how much f changes. This will be the same as moving in the directional derivative,\nsince for linear functions, the slope is the same everywhere.\n\nKey Idea: to compute df/ds, linearize everything, move one unit in s, and see how much that affects f.\n\nThe linearity assumption is the assumes that changes in variables will affect the output independently.\n\nwherever a function has a derivative, it is locally linear\n\nLast Reviewed: 10/27/24\nReference Page: #1"}, {"color": {"background": "#c41e3a", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Infinitesimals/", "id": "Infinitesimals", "label": "Infinitesimals", "mass": 0.25, "shape": "dot", "size": 5.0, "title": "# Infinitesimals\n{% raw %}\n\nSuppose we have a rectangular approximation to a definite integral with limits $a$ and $b$. We take $N$ evenly spaced points $x_1, \\ldots, x_N$, where $x_1 = a$ and $x_N = b$. This corresponds to $N-1$ rectangles. The area under the curve is approximated as:\n\n$$\n\\sum_{i=1}^N f(x) (x_{i+1} - x_{i}) =\n\\sum_{i=1}^N f(x_i) \\Delta x\n$$\n\nWhere $\\Delta x$ is $x_{i+1} - x_{i}$. \n\nAs we take $\\Delta x \\rightarrow 0^+$:\n\n$$\n\\sum_{i=1}^N f(x_i) \\Delta x \\rightarrow \\int_a^b f(x) dx\n$$\n\nThe $dx$ represents an infinitely small change in $x$.\n\nIt is also why\n\n\n$$\n\\int_a^b dx = b - a\n$$\nSince\n\n$$\n\\lim_{\\Delta x \\rightarrow 0} \\left[ \\sum_{i=1}^N f(x_i) \\Delta x \\right] = b - a\n$$\n\nLast Reviewed: 2/4/25\n{% endraw %}\n"}, {"color": {"background": "#c41e3a", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Functions/", "id": "Functions", "label": "Functions", "mass": 0.01, "shape": "dot", "size": 5, "title": "# Functions\n\npolynomials are a linear combination of x, x**2, x**3, as functions\nLast Reviewed: 12/1/24\n"}, {"color": {"background": "#c41e3a", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/posts/A-Brief-Introduction-To-Information/", "id": "A Brief Introduction To Information", "label": "\u201cA Brief Introduction To Information\u201d", "mass": 0.04, "shape": "dot", "size": 5, "title": "# A Brief Introduction To Information\n\n\n- All information is communication - it requires a method of decoding, must be interpreted.\n- All digital info = bits\n- Setup: communicate a sequence of random events\n- The streaming setting (where bits are decoded as they come) requires disambiguous prefixes - I proved this.\n\n[Original Blog Post](https://calvinyluo.com/2019/03/19/a-brief-introduction-to-information.html)\n\nLast Reviewed: 11/9/24\n"}, {"color": "#c41e3a", "fixed": false, "font": {"color": "white"}, "id": "Deep Learning Chapter 3", "label": "\u201cDeep Learning Chapter 3\u201d", "mass": 0.7500000000000001, "shape": "dot", "size": 8.660254037844387, "title": ""}, {"color": {"background": "#c41e3a", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/KL-Divergence/", "id": "KL Divergence", "label": "KL Divergence", "mass": 0.5000000000000001, "shape": "dot", "size": 7.0710678118654755, "title": "# KL-Divergence\nAsymmetric\nDKL(P||Q) - symbols are drawn from P, but if we encode assuming drawn from Q, \nhow many extra bits on expectation are used\nEx~p[log(P(x))-log(Q(x))]\nAsymmetric b/c depends on which distribution you\u0027re sampling from - two examples\n(Should read more)\n\nhow much more suprised you\u0027d be seeing P while expecting Q\nLast Reviewed: 10/27/24\nReference Page: #2\n"}, {"color": {"background": "#c41e3a", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/posts/Six-Interpretations-of-KL-Divergence/", "id": "Six Interpretations of KL Divergence", "label": "\u201cSix Interpretations of KL Divergence\u201d", "mass": 0.25, "shape": "dot", "size": 5.0, "title": "# An Interpretation of KL Divergence\nImagine a lottery game. Let $X$ be a random variable describing the outcome of the lottery game, and $x$ be a realization of that random variable.\n\n- For a bet of $c$ on an outcome $x$, the house pays you $\\frac{c}{q(x)}$ where $q(x)$ is the probability they assign to the outcome $x$.\n- This is the optimal way for *them* to make money, if they believe the true distribution is $q(x)$.\n\nNow, let\u0027s talk about what you do as a player:\n- Suppose you know the true distribution of outcomes $p(x)$.\n- To maximize your winnings, you should bet proportional to $p(x)$.\n- Suppose you bet 1 dollar total.\n- Then you optimally bet $p(x)$ dollars for each outcome.\n\nYour expected log-winnings are:\n\n$$\n\\sum_x\\left[ p(x) \\log \\left(\\frac{p(x)}{q(x)} \\right)\\right]\n$$\n\nThis is actually the formula for KL-divergence.\n\nIn other words, $D_{\\text{KL}(p,q)}$ is the maximum amount of log-money that can be made off one dollar, when the payoffs are assigned by the distribution $q$, but the real distribution is $p$.\n\n\n\u003cspan style=\"color:blue\"\u003eTo Do: review other interpretations\u003c/span\u003e.\n\n[Link][https://www.lesswrong.com/posts/no5jDTut5Byjqb4j5/six-and-a-half-intuitions-for-kl-divergence]\n\nLast Reviewed: 1/20/25\n\n\n\n\n"}, {"color": {"background": "#c41e3a", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Entropy/", "id": "Entropy", "label": "Entropy", "mass": 0.25, "shape": "dot", "size": 5.0, "title": "# Entropy\nExpected information in a distribution\nmeasures uncertainty in a probability distribution\nBernoulli Example\nLast Reviewed: 10/27/24\nReference Sheet #3."}, {"color": {"background": "#c41e3a", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Cross-Entropy/", "id": "Cross Entropy", "label": "Cross Entropy", "mass": 0.25, "shape": "dot", "size": 5.0, "title": "# Cross Entropy\n\n-\u00e2\u02c6\u00ab(p(x) log(q(x) dx))\n\nEntropy is:\n-\u00e2\u02c6\u00ab(p(x) log(p(x) dx))\nCall this Ent(p, p)\n\nCross Entropy is:\n-\u00e2\u02c6\u00ab(p(x) log(q(x) dx))\nCall this Ent(p, q)\n\nKL Divergence is:\n- \u00e2\u02c6\u00ab(p(x) log(q(x) dx)) - (-\u00e2\u02c6\u00ab(p(x) log(p(x) dx)))\nOr\n\u00e2\u02c6\u00ab(p(x) log(q(x) dx))  + \u00e2\u02c6\u00ab(p(x) log(p(x) dx))\n\nThis is Ent(p, q) - Ent(p,p)\n\nWhen we add KL divergence and entropy, we get cross entropy\nCross entropy = number of bits it takes to encode samples from P using an encoding trained on Q\nEntropy = number of bits it takes to encode samples from P using an encoding trained on P\nKL Divergence = number of extra bits it takes to encode samples from P using an encoding trained on Q.\nOr, KL divergence is cross entropy minus entropy.\nLast Reviewed: 1/20/25\n"}, {"color": {"background": "#c41e3a", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Info-Theory-Basics/", "id": "Info Theory Basics", "label": "Info Theory Basics", "mass": 0.25, "shape": "dot", "size": 5.0, "title": "# Info Theory Basics\n\nInformation is -logP(x) for an event\nIndependent events have additive infomration\nLess likely events have higher Information\nknowing outcome of an event with 50% prob has 1 bit of information\nMeasured in nats or bits (recall logs of all bases are proportional)\n0 information if certain\n\nsetup: a bitstream encodes a sequence of random vairables. Prefix requirements impose a cost of 2^l\n\nLast Reviewed: 10/27/24\nReference Sheet #3, 3.1"}, {"color": {"background": "#ff6f20", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Random-Variables-and-Probability-Distributions/", "id": "Random-Variables-and-Probability-Distributions", "label": "Random-Variables-and-Probability-Distributions", "mass": 1.0, "shape": "dot", "size": 10.0, "title": "# Random Variables and Probability Distributions\n\n## Definition of Random Variable\n\n\u003c!-- ### Practical Definition\nIn machine learning, it suffices to think of a random variable simply as a \u0027variable\u0027, or a placeholder for a number or vector. There are notions of probability and randomness associated with it, but these can be associated with other constructs, like probability distributions.\n\nFor instance,\n\n$$\ny = 2z\n$$\nMeans \u0027take the value that $z$ takes, and multiply it by $2$ to get $y$. There is no concept of \u0027randomness\u0027 yet introduced. --\u003e\n\n### Precise Definition\n\nA random variable $X$ is a function from a sample space $\\Omega$ to a set of outcomes $E$.\n\nFor instance, we can assign a random variable to the result of a dice roll, and call it $X$. In this case, the sample space is:\n$$\\Omega = \\{1,2,3,4,5,6\\}$$\n\nThe random variable $X$ is a function such that $X(\\omega) = \\omega$, for $\\omega \\in \\Omega$.\n\n\u003c!-- It might seem redundant to define a random variable as a function, but it is conceptually useful because functions can take on multiple values depending on their input. If we think of $X$ as a function, it is easier to cope with the possibility that $X$ may take on more than one value. --\u003e\n\n### Operators on Random Variables\nIf we assign\n$$\nY = 2X\n$$\n\nWe can think of multiplication by $2$ as an operator on the function $X$ (An operator takes in a function and provides another function).\n\nWe are really saying that $Y$ is a new random variable (a new function), $y \\mapsto Y(\\omega)$, such that\n\n$$\nY(\\omega) = 2X(\\omega) \\quad \\forall \\omega.\n$$\n\nIf $X$ is a random variable representing the value of a dice roll, $Y$ is a random variable representing twice the value of a dice roll.\n\n### More notes on notation\n#### Capital vs. Lowercase\nWhile random variables are represented with capital letters, we typically use the corresponding lower case letter to denote a realization of that random variable. In math terms, we use $x$ to denote $X(\\omega)$. \n\n$$\nx = X(\\omega)\n$$\n\nWhile $X$ is a function, $x$ is a value.\n\nThis is similar to how in mathematicals more generally, if $f$ refers to a function, then $f(x)$ refers to a value, namely, the output of $f$ when its input is $x$, although this distinction is [blurred frequently](https://en.wikipedia.org/wiki/Abuse_of_notation#Function_notation).\n\n#### Bold vs unbolded\nBolded random variables and their values (realizations) simply indicate that the random variable is vector-valued.\n\n\n\n### Sample Spaces in Machine Learning\nThe sample space is not usually referenced in machine learning. For instance, we might have a latent variable $\\mathbf{Z}$ in a latent variable model. If $\\mathbf{z} = \\mathbf{Z}(\\mathbf{w}) \\in \\mathbb{R}^d$, the sample space $\\Omega$ is $\\mathbb{R}^d$, and we think of $\\mathbf{Z} : \\Omega \\rightarrow \\mathbb{R}^d$ as $\\mathbf{Z}(\\omega) = \\omega$.\n\n\n## Probability Distributions\nA probability distribution is a maps random variable ***values*** to densities. Formally, a random variable $\\mathbf{X}$ is a function with an output domain (often $\\mathbb{R}^d$), and the probability density function maps the output domain of $\\mathbf{X}$ to density values in $\\mathbb{R}$.\n$$\np(\\mathbf{x}) : \\mathbb{R}^d \\rightarrow \\mathbb{R}.\n$$\n\nAs an exercise in notation, this means we should also be able to write:\n$$\np\\left(\\mathbf{X}(\\mathbf{\\omega})\\right) : \\mathbb{R}^d \\rightarrow \\mathbb{R}.\n$$\n\nWe abbreviate \"probability density function\" as \"PDF\".\n\n\n#### Note\nIt is not the case that a random variable has a single probability distribution, although we often reference a \"true\" probability distribution. Rather, a probability distribution is simply a mapping from a random variable\u0027s value to a density value.\n\n### Notes on Notation\n#### $Pr(x)$ vs $p(x)$\nTypically, $Pr(A)$ refers to the probability of event $A$, while $p(x)$ refers to the value of the PDF at a data point $x$. Not everyone uses this notation, though.\n\n#### Resolving function vs. value dilemma\nWe often use $f(x)$ to refer to the function $f$, instead of the value of $f$ at $x$. This is also true in statistics. We commonly use\n$$\np(\\mathbf{x})\n$$\n\nTo refer to the probability distribution $p$, even though it should denote the density value of the probability distiribution at the point $\\mathbf{x}$. This is used ubiquitiously, and perhaps the inclusion of $\\mathbf{x}$ helps specify that the distribution\u0027s input are realizations of the random variable $X$. Sometimes, this is important because $p$ may represent a *family* of distributions, not just a single probability distribution.\n\n\n#### Families of Probability Distributions\nIn machine learning, when we write something like $p_\\theta$, we are typically referring to a *family* of probability distributions, not just a single distribution.\n\nFor instance, if we draw $\\mathbf{x_1}, \\ldots , \\mathbf{x}_N$ independently from a data distribution, we can write\n\n$$\np_\\theta(\\mathbf{x_1}, \\ldots , \\mathbf{x}_N) = \\prod_{i=1}^N p_\\theta(\\mathbf{x_i}).\n$$\n\nIn this case, the left hand side refers to the probability of observing $\\mathbf{x}_1, \\ldots , \\mathbf{x}_N$ according to the joint distribution given by the parameters $\\theta$. We use $p_\\theta$ to refer to both the joint *and* marginal distributions. They are intertwined by the rules of probability, e.g., the chain rule.\n\n\n\n\n### Distributions \u0027over\u0027 random variables.\nIf we write\n$$\n\\mathcal{N}_x(0,I)\n$$\nThe $x$ in the subscript indicates that the distribution is \"over\" the random variable realization $x$, as opposed to another random variable. More precisely, $\\mathcal{N}_x(0,I)$ is function mapping $x = X(\\omega)$ to $\\mathbb{R}$. The $x$ denotes what we use as the input to this function.\n\nThis is useful to disambiguate the input to the PDF when we have several PDFs.\n\n#### Example\n\nSuppose we have \n\n$$\np(\\mathbf{x}) = \\int \\mathcal{N}_\\mathbf{x}(f(\\mathbf{z}), I) \\cdot N_\\mathbf{z}(0,I) d\\mathbf{z}.\n$$\nIn this case,\n\n\n- $p(\\mathbf{x})$ is a function mapping $\\mathbf{x}$ to probability values.\n- For a given input $\\mathbf{x}$, we would substitute that value of $\\mathbf{x}$ into $\\mathcal{N}_\\mathbf{x}(f(\\mathbf{z}), I)$ to get a density value.\n- The value of $\\mathbf{z}$ we would use is determined by the integrand.\n\n\nTo evaluate $p(\\mathbf{x})$ for a specific $\\mathbf{x}$, we would:\n1. Iterate through all values of $\\mathbf{z}$\n2. Plug in $f(\\mathbf{z})$ for the these values to get the parameters (mean and variance) for the distribution $\\mathcal{N}_\\mathbf{x}$.\n3. Plug in $\\mathbf{x}$ into this distribution to get a probability density value.\n4. Plug in $\\mathbf{z}$ into $\\mathcal{N}_\\mathbf{z}(0,I)$ to get a probability density value\n5. Multiply the two density values together (the outputs of the two normal distributions) and accumulate it over all $\\mathbf{z}$ to evaluate the integral.\n\nThe parameters $f(\\mathbf{z}), I$ are how we describe the function that is the probability distribution.\n\nLast Reviewed: 1/31/25"}, {"color": {"background": "#ff6f20", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Bayes/", "id": "Bayes", "label": "Bayes", "mass": 1.0, "shape": "dot", "size": 10.0, "title": "# Bayes\nWe can ignore terms that are constant with regard to the distribution we are computing.\nFor instance, for a fixed x*,\n\np(z | x*)  = (p(x* | z) p(z)) / p(x*)\n\nbut we can ignore p(x*) since we are interested in a distribution with respect to z.\nTo get this distribution, we can evaluate p(x* | z) p(z) at all z and ensure it integrates to 1\nby rescaling it by C\nignoring the need for p(x*) term (which is 1/C).\n\nTO DO: Find notes about \u0027evidence\u0027 in Bayes\n\nLast Reviewed: 1/25/25\n\n\n"}, {"color": {"background": "#ff6f20", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Conditional-Independence/", "id": "Conditional Independence", "label": "Conditional Independence", "mass": 0.25, "shape": "dot", "size": 5.0, "title": "# Conditional Independence\nLast Reviewed: 1/25/25\n\ne.g., in diffusion models, we have\n\nq(z_2 | z_1, x) = q(z_2 | z_1)\n\nsince z_1 provides all information needed to compute z_2, thus given z_1 as information,\nz_2 is independent from x, or x provides no \u0027additional information\u0027."}, {"color": "#0000FF", "fixed": false, "font": {"color": "white"}, "id": "Deep Learning", "label": "Deep Learning", "mass": 17.61, "shape": "dot", "size": 41.96427051671457, "title": ""}, {"color": "#212129", "fixed": false, "font": {"color": "white"}, "id": "Software", "label": "Software", "mass": 1.0, "shape": "dot", "size": 10.0, "title": ""}, {"color": {"background": "#35208d", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/softwares/PyTorch/", "id": "PyTorch", "label": "PyTorch", "mass": 1.0, "shape": "dot", "size": 10.0, "title": "# PyTorch\nDatasets:\n---need __len__ and __get_item__\n\nDataloaders\n---collate_fn defines how the different data examples should be turned into a batch\n\nBackwards:\n---fills \"grad\" field of every tensor that requires it\n\nZero_grad\n---turns \"grad\" field of every tensor that requires it to 0\n\noptimizer.step()\n---the optimizer has a bunch of parameters stored in it, and it looks at the gradient of all the parameters\nand then does a backward step\n\n\nUse register_buffer to add a desired tensor to the model, so it gets moved to the right device.\npersistent=False will make it not part of the state_dict.\nLast Reviewed: 1/20/25"}, {"color": "#0000ff", "fixed": false, "font": {"color": "white"}, "id": "Activation Functions", "label": "Activation Functions", "mass": 0.08000000000000002, "shape": "dot", "size": 5, "title": ""}, {"color": {"background": "#0000ff", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Pocketed-Activations/", "id": "Pocketed Activations", "label": "Pocketed Activations", "mass": 0.04, "shape": "dot", "size": 5, "title": "# Pocketed Activation\nLast Reviewed: 1/3/25\n\nDead ReLU problem - activation ranges get super negative\nPocketed Activation (Swish, Mish) - activations get stuck in pocket, since it\u0027s a local minima\nEnough examples can remove from pocket\n\nGeLU is the same as setting the dropout probabilty to the CDF of the neuron value, and taking the expectation\n\nThink about this more"}, {"color": {"background": "#0000ff", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Gated-Activations/", "id": "Gated Activations", "label": "Gated Activations", "mass": 0.04, "shape": "dot", "size": 5, "title": "# Gated Activations\n\nGLU = (Ax + b)*sigma(Cx + D)\nSwiGLU = (Ax + b)*swish(Cx + D)\nSwiGLU has this squared part (derivative vanishes near zero)\nReLU^2 also does well, perhaps due to this square part\nSnake has an x^2 term in its expansion\n\nLast Reviewed: 1/17/25\n"}, {"color": "#0000ff", "fixed": false, "font": {"color": "white"}, "id": "Understanding Deep Learning", "label": "\u201cUnderstanding Deep Learning\u201d", "mass": 7.32, "shape": "dot", "size": 27.055498516937366, "title": ""}, {"color": {"background": "#0000ff", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/chapters/MLP-Interpretation-UDL/", "id": "MLP Interpretation - UDL", "label": "\u201cMLP Interpretation - UDL\u201d", "mass": 1.0, "shape": "dot", "size": 10.0, "title": "Last Recall: 10/24/24\n# MLP Interpretation - UDL\n- Shallow MLPs clip linear functions, rescale, and combine.\n- $D$ hidden units means $D+1$ Linear Regions\n- Multivariate outputs are all clipped at the same joints\n- There\u0027s a Multivariate Input Visualization in the book\n- All ReLU MLPs split input space into Linear Regions\n- \"Folding\" interpretation\n- Adding a Layer is clipping Each Linear Region, and recombining\n- Bottlenecks are restricting weights to outer product\n- Depth efficiency is exponential compared to width efficiency\n- Depth generalizes and trains better\n- Swishes solve Dying ReLU\n- Weights can be rescaled as long as biases are too\n- Depth approximation theorem\n\nLast Reviewed: 11/1/24\n"}, {"color": {"background": "#0000ff", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/chapters/Loss-Functions-UDL/", "id": "Loss Functions - UDL", "label": "\u201cLoss Functions - UDL\u201d", "mass": 1.0, "shape": "dot", "size": 10.0, "title": "# Loss Functions - UDL\n\nBelow are some brief notes on loss functions from Understanding Deep Learning.\n\n- Most losses are some form of negative log likelihood.\n- There is a \u0027formula\u0027 for writing loss functions:\n    - Model predicts parameters of a distribution, on which the probability of data is evaluated.\n    - Maximize probability of data, or minimize negative log probability of data.\n- Assume data is independent \n  - Assume the value of one datapoint does not affect the value of another (after the model is optimized)\n  - The probability of observing all your datapoints is the product of the probabilities of observing each of your individual datapoints.\n\n## MSE Loss\n- MSE results from assuming y is sampled from gaussians with means determined by x\n- In the heterodastic MSE, the variance of the output varies with the input\n\n## BCE Loss\n- BCE loss comes from assuming the distribution $p(y \\mid x)$ is Bernoulli (there\u0027s a visualization)\n- Multiclass cross entropy loss is discussed here as well\n- There is a table of distributions, and their usage in different tasks.\n\n## Other Notes\n- In multi-output situations, assume different outputs are conditionally independent given the input.\n- NLL minimization is the same as minimizing cross entropy between (possibly conditional on input) data distributions. This is really cool!\n\nReference Sheet: UDL Chapter 5\nLast Reviewed: 11/1/24"}, {"color": "#FFD900", "fixed": false, "font": {"color": "white"}, "id": "Generative Modeling", "label": "Generative Modeling", "mass": 11.550000000000002, "shape": "dot", "size": 33.98529093593286, "title": ""}, {"color": {"background": "#c876a3", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/chapters/VAEs-UDL/", "id": "VAEs - UDL", "label": "\u201cVAEs - UDL\u201d", "mass": 1.32, "shape": "dot", "size": 11.489125293076057, "title": "# VAEs - UDL\n\n\u003cspan style=\"color:blue\"\u003eTo Do: Organize\u003c/span\u003e.\n\n\u003cspan style=\"color:blue\"\u003eTo Do: Insert ELBO Math\u003c/span\u003e.\n\n## Introduction\n- VAEs do not let you evaluate p(x)\n- MLE training is not trivial, but can define a lower bound\n- model an \u0027unobserved\u0027 latent variable, the thing that \u0027gives rise\u0027 to the image/sound\n- p(x) = integral(P(x,z)dz) = integral(p(x|z)p(z)dz)\nExample - Mixture of Gaussians, z describes which gaussian.\n\nVAE - P(z) is N(O,I), and P(x|z) is N(f(z), s^2I)\nIn other words, z maps to a gaussian\u0027s mean, and the distribution is a marginalization of all these gaussians over z.\n\nSee image where one distribution is made up of as a \u0027marginalization\u0027 (sum) of gaussians\n\nGeneration: sample from P(z) then P(x|z)\n\nEvaluating/maximizing p(x) slash sum(log(p(x)))is intractable.\n\nA model that maximizes it could try to assign big probabilities to your data, without being restricted to \nintegrating to 1.\n\nTrying to restrict it to integrate to 1 is intractable.\n\n\nNote:\np(z|x) is the \u0027posterior.\u0027 What could the latent variable be after observing x?\np(z) is the \u0027prior\u0027 on the latent variable.\np(x|z) is the \u0027likelihood\u0027. This helps us evaluate the Posterior, since we want to see, for each value of z,\nwhat is the probability we could have gotten that x? it\u0027s detective work.\nTo evaluate the posterior, Bayes Rule would say:\n\np(z|x) = p(x|z)p(z)/p(x).\nBut really, we only need the numerator, since we can make it integrate to 1, and p(x) does not determine the\nrelative probabilites of the z\u0027s.\n1---Compute p(x|z) for each value of z\n2---multiply by p(z)\n3---normalize so the posterior p(z|x) sums to 1\nThere\u0027s a diagram of this in UDL.\n\np(x) is called the evidence\nLast Reviewed: 1/19/25\n"}, {"color": {"background": "#e87267", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/ELBO/", "id": "ELBO", "label": "ELBO", "mass": 0.32000000000000006, "shape": "dot", "size": 5.656854249492381, "title": "# Downsampling and Stretching\nLots of math here. You can reprove this by hand from Jensen\u0027s inequality or look at your notes\n\nBasically, start with log(p(x)).\n---Then express it using a latent variable model decomposition\n---choose an arbitrary q(z) as your \u0027weighting\u0027\nint(  log(    q(z) * p(x,z)/q(z)         )  dz)\n---apply Jensen\u0027s inequality\nwhen you get to p(x,z) split it up into p(z|x) and p(x)\nthat will let you take out p(x), and also give you a KL term\n\nELBO = log(p(x)) - KL(q(z), p(z|x))) (this KL is assuming q is \u0027ground truth\u0027)\n\nMaximizing p(x) with respect to the parameters for q(z) and p(z|x) involves expectation maximization, this means\n---can improve ELBO\u0027s lower bound by changing p(z|x) slash p(x|z)\u0027s parametrization\nOR\n---can make ELBO bound more tight by changing q(z)\u0027s parametrization\nLast Reviewed: 1/19/25"}, {"color": {"background": "#e87267", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Jensens-Inequality/", "id": "Jensens Inequality", "label": "Jensens Inequality", "mass": 0.16, "shape": "dot", "size": 5, "title": "# Jensens Inequality\n\nImagine a bunch of datapoints lying on log(y)\n\nImagine a point (E[y], E[log[y]])\n\nThis is the midpoint of all the datapoints\nThis will lie under the log(y) curve by concavity:\nf((1-a)x + a*y) \u003e= (1-a)f(x) + a*f(y)\n\nThe midpoint will lie under the log curve\nIt is thus lower than\n\n(E[y], log(E[y])) which is on the curve.\n\nTo Do: Prove Jensen\u0027s Inequality\nLast Reviewed: 1/19/25\n\n\n\n"}, {"color": {"background": "#c63598", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/chapters/Optimization-UDL/", "id": "Optimization - UDL", "label": "\u201cOptimization - UDL\u201d", "mass": 1.0, "shape": "dot", "size": 10.0, "title": "# Optimization - UDL\n\n\u003cspan style=\"color:blue\"\u003eTo Do: Fill this out\u003c/span\u003e.\n\nLast Reviewed: 11/9/24\nReference Sheet: UDL Chapter 6\n"}, {"color": "#ffd900", "fixed": false, "font": {"color": "white"}, "id": "Diffusion Models", "label": "Diffusion Models", "mass": 9.74, "shape": "dot", "size": 31.20897306865447, "title": ""}, {"color": {"background": "#c876a3", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/chapters/DDPM-UDL/", "id": "DDPM - UDL", "label": "\u201cDDPM - UDL\u201d", "mass": 3.0000000000000004, "shape": "dot", "size": 17.320508075688775, "title": "# Diffusion Models - UDL Notes\n{% raw %}\n\n## Introduction\n\u003cspan style=\"color:blue\"\u003eTo Do: Write Introduction\u003c/span\u003e\n\n\nDiffusion models can be interpreted as Hierarchical VAEs. The encoder in this case has no learnable parameters, and gradually adds noise to data. The decoder attempts to reverse this process.\n\n## DDPM - Noise Schedule\nLet $\\mathbf{X}$ the random variable representing a data sample from the intended distribution, and $\\mathbf{x}$ be a realization of it. Also, define\n\n$$\\mathbf{Z_0} \\coloneqq \\mathbf{X}$$\n\nWe have latent variables $\\mathbf{z_1}, \\ldots, \\mathbf{z_T} $ correponding to noise levels $1, \\ldots, T$. These latent variables are given by:\n\n$$\n\\mathbf{z_t} = \\sqrt{1 - \\beta_t }\\mathbf{z_{t-1}} + \\sqrt{\\beta_t}\\mathbf{\\epsilon}_t\n$$\n\nwhere $ \\mathbf{\\epsilon}_t\\sim \\mathcal{N}(0,I) $.\n\n### Marginal Distributions\nComputing $\\mathbf{q}(\\mathbf{x}_t \\mid \\mathbf{x})$ is like adding a noise level corresponding to $t$ to our data. The formulas above allow us to generate these by iteratively adding noise. However, we can actually directly compute the marginal distributions in closed form:\n\n$$\n\\mathbf{q}(\\mathbf{x}_t \\mid \\mathbf{x})\n$$\n\n(where we are marginalizing over $\\mathbf{z}_1,\\ldots, \\mathbf{z}_{t-1}$).\n\nWe can do this by working inductively.\n\n\u003cspan style=\"color:blue\"\u003eTo Do: Insert Inductive Proof\u003c/span\u003e.\n\nTo summarize, we define\n\n$$\n\\alpha_t = \\prod_{i=1}^t (1 - \\beta_t)\n$$\n\nAnd discover that\n\n$$\n\\mathbf{q}(\\mathbf{x}_t \\mid \\mathbf{x}) = \\mathcal{N}(\\sqrt{\\alpha_t} \\mathbf{x}, (1-\\alpha_t) \\mathbf{I})\n$$\n\n\n## DDPM - Derivation of Objective\nWe would like to maximize the log probability of our data under our generative model. We show we can express an ELBO of our objective as a weighted sum of MSE losses from a sample of $\\mathbf{z}_{t-1} \\sim p(\\mathbf{z}_{t-1} \\mid \\mathbf{x})$ and a prediction of that sample obtained from a learned function on  $\\mathbf{z}_{t}$. In other words, the objective is to predict $\\mathbf{z}_{t-1}$ from $\\mathbf{z}_{t}$, or to denoise the data one step.\n\nThis [DDPM Math](DDPM-Math.md) is shown here.\n\nIn practice, we express the function $\\mathbf{f}$ as as a linear combination of $\\mathbf{z}_{t-1}$ and a noise term $\\mathbf{\\epsilon}_t \\sim \\mathcal{N}(0,\\mathbf{I})$.\n\nWe use a neural network $\\mathbf{g_\\theta}$ to predict the noise term $\\mathbf{\\epsilon}_t \\sim \\mathcal{N}(0,\\mathbf{I})$. This leads to a [reparametrization, and a method of training and inference for DDPMs](DDPM-Reparametrization.md).\n\n\n## Why Does Diffusion Work?\n\n\n### Modeling Multi-modal distributions\nGenerative modeling is about turning simple distributions (noise) into more complex ones (data). \n- The data distribution is very complex and multimodal. But we can assume each denoising step $p(\\mathbf{z}_{t-1} | \\mathbf{z}_t)$ is approximately normal.\n- VAEs attempt to map $\\mathcal{N}(0,I)$ to a data distribution with potentially many modes. This is easier to do when each timestep increases the number of modes.\n- We sample from a normal distribution at **each reverse time-step**, which eventually allows us to be in a particular \u0027modes\u0027 of the distirbution.\n- This eventually allows us to model a multimodal distribution.\n- Metaphorically, each sampling step allows you to guides you towards a specific path or another.\n- Eventually, you\u0027ll fall into one of the modes of the distribution, but due to stochasticity, we hope to see *all* of them\n\n### Plinko\nThe game [Plinko](https://spribe.co/games/plinko) is a good analogy.\n\n- Higher layers in Plinko are the higher noise levels.\n- Instead of each stick outputting \u0027left\u0027 or \u0027right\u0027 with 50/50 probability, the stick steers it in a certain direction.\n\nWhen we extend this analogy to diffusion when the number of timesteps is infinite, we get something like Brownian Motion.\n\n- If we instead imagine an infinite number of sticks at an infinite number of heights, we have a simulation of Brownian motion or a [Wiener Process](../concepts/Wiener-Process).\n- The ball moves randomly at *every* time\n- The ball become a \u0027particle\u0027 randomly colliding with other particles (but moving down due to gravity, which is like moving forward in time.)\n\n\n## Notes on Optimization\n- We would like our model to predict $q(\\mathbf{z}_{t-1} \\mid \\mathbf{z}_{t})$, where $q$ is the probability distribution given by the deterministic encoder.\n- However, we don\u0027t have supervision for this.\n- We can compute $q(\\mathbf{z}_{t-1} \\mid \\mathbf{z}_t, \\mathbf{x})$.\n    - This is a Gaussian whose mean is near $\\mathbf{z}_t$, but a little further from 0 due to the drift term $\\sqrt{1-\\beta_t}$ applied to the mean of the data during the forward process.\n\n- This guides $p_\\theta(\\mathbf{z}_{t-1}, \\mathbf{z}_t)$ toward $\\mathbb{E}_{\\mathbf{x} \\sim p(\\mathbf{x})} q(\\mathbf{z}_{t-1} \\mid \\mathbf{z}_t, \\mathbf{x}) = q(\\mathbf{z}_{t-1} \\mid \\mathbf{z}_t, \\mathbf{x})$\n- It is possible to approximate the expectation term above using Monte-Carlo sampling.\n- In other words, we are guiding $p_\\theta(\\mathbf{z}_{t-1})$ with $q(\\mathbf{z}_{t-1} \\mid \\mathbf{z}_t, \\mathbf{x})$, where samples $\\mathbf{x}$ are drawn from the data, but since the model cannot see $\\mathbf{x}$, it will fit $q(\\mathbf{z}_{t-1} \\mid \\mathbf{z}_{t})$.\n\n\nSee math in \"DiffusionMath\"\n\nLast Reviewed: 1/23/25\n\n\nMore Resources I should look at:\nhttps://sander.ai/2024/09/02/spectral-autoregression.html\nhttps://sander.ai/2023/07/20/perspectives.html\n\n{% endraw %}\n"}, {"color": {"background": "#c876a3", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/chapters/DDPM-Math/", "id": "DDPM - Math", "label": "\u201cDDPM - Math\u201d", "mass": 1.0, "shape": "dot", "size": 10.0, "title": "# DDPM Math\n{% raw %}\n\n### Main Expression\n$$\n\\log p_\\theta(\\mathbf{x}) = \\log \\int_{\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T}} p_\\theta(\\mathbf{x},\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T} )d\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T}\n$$\n\n$$\n= \\log \\int_{\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T}} \\frac{p_\\theta(\\mathbf{x},\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T} )}{q(\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T}|\\mathbf{x})} q(\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T}|\\mathbf{x})d\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T}\n$$\n\n$$\n\\geq \\int_{\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T}} \\log \\left[ \\frac{p_\\theta(\\mathbf{x},\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T} )}{q(\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T}|\\mathbf{x})} \\right] q(\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T}|\\mathbf{x})d\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T}\n$$\n\n### Focusing on the Numerator in the log\n\nNow,\n\n$$\np_\\theta(\\mathbf{x},\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T} )=p_\\theta(\\mathbf{x}|\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T})p_\\theta(\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T})\n$$\n\nWe have parametrized the decoder such that $p_\\theta(\\mathbf{x}|\\mathbf{z}_1)$ is conditionally independent from $\\mathbf{z}_2,\u00e2\u20ac\u00a6.,\\mathbf{z}_T$. We call this the Markov property of $p$. This is:\n\n$$\n= p_\\theta(\\mathbf{x}|\\mathbf{z}_1)p_\\theta(\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T})\n$$\n\nExpanding by using the Chain Rule:\n\n$$\np_\\theta(\\mathbf{x}|\\mathbf{z}_1 )p_\\theta(\\mathbf{z}_1|\\mathbf{z}_{2,\u00e2\u20ac\u00a6,T})p_\\theta(\\mathbf{z}_{2,\u00e2\u20ac\u00a6,T})\n$$\n\nOnce again, using the Markov property of $p$:\n\n$$\np_\\theta(\\mathbf{x}|\\mathbf{z}_1 )p_\\theta(\\mathbf{z}_1|\\mathbf{z}_2 )p_\\theta(\\mathbf{z}_{2,\u00e2\u20ac\u00a6,T})\n$$\n\nContinuing, we get \n\n$$\np_\\theta(\\mathbf{x}|\\mathbf{z}_1 )p_\\theta(\\mathbf{z}_1|\\mathbf{z}_2 )p_\\theta(\\mathbf{z}_2|\\mathbf{z}_3 )\\dots p_\\theta(\\mathbf{z}_{T-1}|\\mathbf{z}_T )p_\\theta(\\mathbf{z}_T )\n$$\n\nThus, the probability of taking a particular path from $\\mathbf{z}_T$ to $\\mathbf{x}$ is given by the above expression. Which is typical, this is just the chain rule applied to Markov chain.\n\n#### One way to put this:\nThe integrals iterate over all possible values of $ \\mathbf{z}_1, \\dots, \\mathbf{z}_T$. They are then plugged in for the e\\mathbf{x}pression for the joint distribution \\( p_\\theta(\\mathbf{x}, \\mathbf{z}_{1,\\dots,T}) \\) to get a probability value, which accumulates across the loop. \\( p_\\theta(\\mathbf{x}, \\mathbf{z}_{1,\\dots,T}) \\) maps a tuple of values \\( (\\mathbf{x}, \\mathbf{z}_{1,\\dots,T}) \\) to a density value based on the joint distribution.\n\nHowever, given this same tuple, \\( (\\mathbf{x}, \\mathbf{z}_{1,\\dots,T}) \\), we can evaluate the density by evaluating the probability density of the \u00e2\u20ac\u02dcpath\u00e2\u20ac\u2122 that goes from \\( \\mathbf{z}_T \\) to \\( \\mathbf{x} \\), which is this e\\mathbf{x}pression:\n\n$$\np_\\theta(\\mathbf{x} | \\mathbf{z}_1) p_\\theta(\\mathbf{z}_1 | \\mathbf{z}_2) p_\\theta(\\mathbf{z}_2 | \\mathbf{z}_3) \\dots p_\\theta(\\mathbf{z}_{T-1} | \\mathbf{z}_T) p_\\theta(\\mathbf{z}_T)\n$$\n\nWhich is the probability that the decoder takes that \u00e2\u20ac\u02dcpath\u00e2\u20ac\u2122 from \\( \\mathbf{z}_T \\) to \\( \\mathbf{x} \\).\n\n\n### Focusing on the Denominator in the log\n\nNow consider:\n\n$$\nq(\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T}|\\mathbf{x})\n$$\n\n$$\n= q(\\mathbf{z}_T |\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T-1},\\mathbf{x})q(\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T-1} |\\mathbf{x})\n$$\n\nSince the forward process is a Markov Chain:\n\n$$\nq(\\mathbf{z}_T |\\mathbf{z}_{T-1})q(\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T-1} |\\mathbf{x})\n$$\n\nContinuing:\n\n$$\nq(\\mathbf{z}_T |\\mathbf{z}_{T-1})q(\\mathbf{z}_{T-1}|\\mathbf{z}_{T-2}) \\dots q(\\mathbf{z}_1|\\mathbf{x})\n$$\n\nThus, evaluating $q(\\mathbf{z}_{1,\u00e2\u20ac\u00a6,T}|\\mathbf{x})$ involves starting with $\\mathbf{x}$, and evaluating the probability fo the chain of events leading from $\\mathbf{x}$ to $\\mathbf{z}_T$.\n\n#### Using Bayes\u0027 rule:\n\n$$\nq(\\mathbf{z}_t|\\mathbf{z}_{t-1}) = q(\\mathbf{z}_t|\\mathbf{z}_{t-1},\\mathbf{x}) = \\frac{q(\\mathbf{z}_{t-1}|\\mathbf{z}_t)q(\\mathbf{z}_t|\\mathbf{x})}{q(\\mathbf{z}_{t-1}|\\mathbf{x})}\n$$\n\n\n$$\nq(\\mathbf{z}_t| \\mathbf{z}_{t-1})=q\\left(\\mathbf{z}_t| \\mathbf{z}_{t-1},\\mathbf{x}\\right)=\\frac{q\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)q\\left(\\mathbf{z}_t| \\mathbf{x}\\right)}{q\\left(\\mathbf{z}_{t-1}| \\mathbf{x}\\right)}$$\n\nThe first step seems like a hack \u00e2\u20ac\u201c since $\\mathbf{z}_t$ conditioned on $\\mathbf{z}_{t-1}$ is independent from $\\mathbf{x}$, we can add in the extra condition on $\\mathbf{x}$ without worrying.\nThus,\n$$\nq\\left(\\mathbf{z}_T\\middle| \\mathbf{z}_{T-1}\\right)q\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_{T-2}\\right)\\cdots q\\left(\\mathbf{z}_2| \\mathbf{z}_1\\right)q\\left(\\mathbf{z}_1| \\mathbf{x}\\right)=\\\\[10pt]\\frac{q\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)q\\left(\\mathbf{z}_T| \\mathbf{x}\\right)}{q\\left(\\mathbf{z}_{T-1}| \\mathbf{x}\\right)}\\cdots\\frac{q\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right)q\\left(\\mathbf{z}_2| \\mathbf{x}\\right)}{q\\left(\\mathbf{z}_1| \\mathbf{x}\\right)}q\\left(\\mathbf{z}_1| \\mathbf{x}\\right)\n=\\\\[10pt]q\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)\\cdots q\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right)\\cdot\\frac{\\left[q\\left(\\mathbf{z}_T| \\mathbf{x}\\right)\\ q\\left(\\mathbf{z}_{T-1\\ }| \\mathbf{x}\\right)\\cdots q\\left(\\mathbf{z}_2| \\mathbf{x}\\right)q\\left(\\mathbf{z}_1| \\mathbf{x}\\right)\\right]}{q\\left(\\mathbf{z}_{T-1}| \\mathbf{x}\\right)\\cdots q\\left(\\mathbf{z}_1| \\mathbf{x}\\right)}\n=\\\\[10pt]q\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right)\\cdots\\ q\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)\\cdot\\frac{\\left[q\\left(\\mathbf{z}_T| \\mathbf{x}\\right)\\ q\\left(\\mathbf{z}_{T-1\\ }| \\mathbf{x}\\right)\\cdots q\\left(\\mathbf{z}_2| \\mathbf{x}\\right)q\\left(\\mathbf{z}_1| \\mathbf{x}\\right)\\right]}{q\\left(\\mathbf{z}_{T-1}| \\mathbf{x}\\right)\\cdots q\\left(\\mathbf{z}_1| \\mathbf{x}\\right)}$$\n\nThings cancel in the fraction:\n$$\n=q\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right)\\cdots\\ q\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)\\cdot q\\left(\\mathbf{z}_T| \\mathbf{x}\\right)\n$$\n\n### Focusing on the log part\nPutting this together, we have\n$$\n\\log{\\left[\\frac{p_\\theta\\left(\\mathbf{x},\\ \\mathbf{z}_{1,\\ldots,T}\\right)}{q\\left(\\mathbf{z}_{1,\\ldots,T} | \\mathbf{x}\\right)}\\right]}=\\ \\log{\\left[\\frac{p_\\theta\\left(\\mathbf{x}| \\mathbf{z}_1\\right)p_\\theta\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right)p_\\theta\\left(\\mathbf{z}_2| \\mathbf{z}_3\\right)\\cdots\\ p_\\theta\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)p_\\theta\\left(\\mathbf{z}_T\\right)}{q\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right)\\cdots\\ q\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)\\cdot q\\left(\\mathbf{z}_T| \\mathbf{x}\\right)}\\right]}\n$$\n$$\n=\\log{\\left[\\frac{p_\\theta\\left(\\mathbf{x}| \\mathbf{z}_1\\right)p_\\theta\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right)p_\\theta\\left(\\mathbf{z}_2| \\mathbf{z}_3\\right)\\cdots\\ p_\\theta\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)p_\\theta\\left(\\mathbf{z}_T\\right)}{q\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right)\\cdots\\ q\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)\\cdot q\\left(\\mathbf{z}_T| \\mathbf{x}\\right)}\\right]}\n$$\n$$\n=\\log{p_\\theta\\left(\\mathbf{x}| \\mathbf{z}_1\\right)}+\\log{\\frac{p_\\theta\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right)}{q\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right)}+\\cdots}\\ \\log{\\frac{p_\\theta\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)}{q\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)}}+\\log{\\frac{p_\\theta\\left(\\mathbf{z}_T\\right)}{q\\left(\\mathbf{z}_T| \\mathbf{x}\\right)}}\n$$\nAssume the last term goes to zero, since the distribution after all the forward diffusion steps should be very similar to $p_\\theta\\left(\\mathbf{z}_T\\right)=\\mathcal{N}\\left(0,\\mathbf{I}\\right)$.\n\nWhy is the distribution for $p_\\theta\\left(\\mathbf{z}_T\\right)=N\\left(0,\\mathbf{I}\\right)?$ Well, we can choose it to be that way, by making the \u00e2\u20ac\u02dcdecoder\u00e2\u20ac\u2122 evaluate it as such. Or, we can think of p as attempting to fit the \u00e2\u20ac\u02dctrue\u00e2\u20ac\u2122 distribution of the data, which is done approximately in this case by being $\\mathcal{N}\\left(0,\\mathbf{I}\\right)$.\n$$\\approx\\log{p_\\theta\\left(\\mathbf{x}| \\mathbf{z}_1\\right)}+\\log{\\frac{p_\\theta\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right)}{q\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right)}+\\cdots}\\ \\log{\\frac{p_\\theta\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)}{q\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)}}$$\nLet us put this in the integral:\n\n### Back to Main Expression\n$$\n\\int_{\\mathbf{z}_{1,\\ldots,T}}{\\left[\\log{p_\\theta\\left(\\mathbf{x}| \\mathbf{z}_1\\right)}+\\log{\\frac{p_\\theta\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right)}{q\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right)}+\\cdots}\\ \\log{\\frac{p_\\theta\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)}{q\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)}}\\right]q\\left(\\mathbf{z}_{1,\\ldots,T}| \\mathbf{x}\\right)d\\mathbf{z}_{1,\\ldots,T}}\n$$\n$$\n\\int_{\\mathbf{z}_{1,\\ldots,T}}\\log{\\left[p_\\theta\\left(\\mathbf{x}| \\mathbf{z}_1\\right)\\right]}q\\left(\\mathbf{z}_{1,\\ldots,T}| \\mathbf{x}\\right)d\\mathbf{z}_{1,\\ldots,T} + \\\\[10pt]\n\\int_{\\mathbf{z}_{1,\\ldots,T}}{\\log{\\left[\\frac{p_\\theta\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right)}{q\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right)}\\right]}q\\left(\\mathbf{z}_{1,\\ldots,T}| \\mathbf{x}\\right)}d\\mathbf{z}_{1,\\ldots,T} + \\\\[10pt]\\cdots+\\int_{\\mathbf{z}_{1,\\ldots,T}}{\\log{\\left[\\frac{p_\\theta\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)}{q\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)}\\right]}q\\left(\\mathbf{z}_{1,\\ldots,T}| \\mathbf{x}\\right)}d\\mathbf{z}_{1,\\ldots,T}\n$$\nWe can marginalize out a lot of stuff. Here is an example.\n### Single Term\n$$\n\\int_{\\mathbf{z}_{1,\\ldots,T}}{\\log{\\left[\\frac{p_\\theta\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)}{q\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)}\\right]}q\\left(\\mathbf{z}_{1,\\ldots,T}| \\mathbf{x}\\right)d\\mathbf{z}_{1,\\ldots,T}}=\\\\[10pt]\n\\int_{\\mathbf{z}_{1,\\ldots,T}}{\\log{\\left[\\frac{p_\\theta\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)}{q\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)}\\right]}q\\left(\\mathbf{z}_{t-1},\\mathbf{z}_t| \\mathbf{x}\\right)q\\left(\\mathbf{z}_{1,\\ldots t-2,\\ t+1,T}| \\mathbf{x},\\ \\mathbf{z}_{t-1},\\mathbf{z}_t\\right)}d\\mathbf{z}_{1,\\ldots,T}\n\\\\[10pt]=\\int_{\\mathbf{z}_{1,\\ldots,T}}{\\log{\\left[\\frac{p_\\theta\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)}{q\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)}\\right]}q\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t,\\ \\mathbf{x}\\right)q\\left(\\mathbf{z}_t| \\mathbf{x}\\right)q\\left(\\mathbf{z}_{1,\\ldots t-2,\\ t+1,T}| \\mathbf{x},\\ \\mathbf{z}_{t-1},\\mathbf{z}_t\\right)}d\\mathbf{z}_{1,\\ldots,T}\n\\\\[10pt]\n=\\int_{\\mathbf{z}_t}\\int_{\\mathbf{z}_{t-1}}\\int_{\\mathbf{z}_{1,\\ldots,t-2,t+1,\\ldots,T}}{\\log{\\left[\\frac{p_\\theta\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)}{q\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)}\\right]}q\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t,\\ \\mathbf{x}\\right)q\\left(\\mathbf{z}_t| \\mathbf{x}\\right)q\\left(\\mathbf{z}_{1,\\ldots t-2,\\ t+1,T}| \\mathbf{x},\\ \\mathbf{z}_{t-1},\\mathbf{z}_t\\right)}d\\mathbf{z}_{1,\\ldots t-2,\\ t+1,T}d\\mathbf{z}_{t-1}{dz}_t\n\\\\[10pt]\n=\\int_{\\mathbf{z}_t}\\int_{\\mathbf{z}_{t-1}}{\\log{\\left[\\frac{p_\\theta\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)}{q\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)}\\right]}q\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t,\\ \\mathbf{x}\\right)q\\left(\\mathbf{z}_t| \\mathbf{x}\\right)\\left\\{\\int_{\\mathbf{z}_{1,\\ldots,t-2,t+1,\\ldots,T}} q\\left(\\mathbf{z}_{1,\\ldots t-2,\\ t+1,T}| \\mathbf{x},\\ \\mathbf{z}_{t-1},\\mathbf{z}_t\\right)d\\mathbf{z}_{1,\\ldots,t-2,t+1,\\ldots,T}\\right\\}}d\\mathbf{z}_{t-1}{dz}_t\n$$\nThe stuff in the brackets goes to 1, since all conditional distributions are still distributions, they integrate to 1 over their input variable(s).\n\n$$\n=\\int_{\\mathbf{z}_t}\\int_{\\mathbf{z}_{t-1}}{\\log{\\left[\\frac{p_\\theta\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)}{q\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)}\\right]}q\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t,\\ \\mathbf{x}\\right)q\\left(\\mathbf{z}_t| \\mathbf{x}\\right)}d\\mathbf{z}_{t-1}{dz}_t\n$$\n$$\n=\\int_{\\mathbf{z}_t}{\\left\\{\\int_{\\mathbf{z}_{t-1}}{\\log{\\left[\\frac{p_\\theta\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)}{q\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)}\\right]}q\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t,\\ \\mathbf{x}\\right)d\\mathbf{z}_{t-1}}\\right\\}q\\left(\\mathbf{z}_t| \\mathbf{x}\\right)}{dz}_t$$\nThe term in the middle is a KL expression:\n$$=\n-\\int_{\\mathbf{z}_t}{D_{KL}\\left[q\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)\\ || \\ p_\\theta\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)\\right]q\\left(\\mathbf{z}_t| \\mathbf{x}\\right)}{dz}_t\n$$\n$$\n= -E_{\\mathbf{z}_t \\sim  q\\left(\\mathbf{z}_t| \\mathbf{x}\\right)}\\left[D_{KL}\\left(q\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right) || p_\\theta\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)\\right)\\ \\right]\n$$\n### Back to Main Expression\n$$\n\\int_{\\mathbf{z}_{1,\\ldots,T}}\\log{\\left[p_\\theta\\left(\\mathbf{x}| \\mathbf{z}_1\\right)\\right]}q\\left(\\mathbf{z}_{1,\\ldots,T}| \\mathbf{x}\\right)d\\mathbf{z}_{1,\\ldots,T}\n$$\n$$\n-E_{\\mathbf{z}_2\\sim q\\left(\\mathbf{z}_2| \\mathbf{x}\\right)}\\left[D_{KL}\\left(q\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right) || p_\\theta\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right)\\right)\\ \\right] -  \n$$\n$$\n\\cdots-E_{\\mathbf{z}_T\\sim q\\left(\\mathbf{z}_T| \\mathbf{x}\\right)}\\left[D_{KL}\\left(q\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right) ||\\ \\ p_\\theta\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)\\right)\\ \\right]\n$$\nMarginalizing the first term (won\u00e2\u20ac\u2122t show the whole thing this time):\n$$\n\\int_{\\mathbf{z}_1}{\\log{\\left[p_\\theta\\left(\\mathbf{x}| \\mathbf{z}_1\\right)\\right]}q\\left(\\mathbf{z}_1| \\mathbf{x}\\right)d\\mathbf{z}_1}\n$$\n$$-E_{\\mathbf{z}_2\\sim q\\left(\\mathbf{z}_2| \\mathbf{x}\\right)}\\left[D_{KL}\\left(q\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right) ||\\ \\ p_\\theta\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right)\\right)\\ \\right] - \\cdots -\n$$\n$$\nE_{\\mathbf{z}_T\\sim q\\left(\\mathbf{z}_T| \\mathbf{x}\\right)}\\left[D_{KL}\\left(q\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right) ||\\ \\ p_\\theta\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)\\right)\\ \\right]\n$$\nTurning the first term into an expectation:\n$$\n=E_{\\mathbf{z}_1\\sim q\\left(\\mathbf{z}_1| \\mathbf{x}\\right)}\\left[\\log p_\\theta \\left(\\mathbf{x}| \\mathbf{z}_1\\right)\\right] - \n$$\n$$E_{\\mathbf{z}_2\\sim q\\left(\\mathbf{z}_2| \\mathbf{x}\\right)}\\left[D_{KL}\\left(q\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right) ||\\ \\ p_\\theta\\left(\\mathbf{z}_1| \\mathbf{z}_2\\right)\\right)\\ \\right] - \n$$\n$$\n\\cdots - E_{\\mathbf{z}_T\\sim q\\left(\\mathbf{z}_T| \\mathbf{x}\\right)}\\left[D_{KL}\\left(q\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right) ||\\ \\ p_\\theta\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)\\right)\\ \\right]\n$$\n\n### Focusing on the Later KL Terms\nAccording to our parametrization, we have\n$$\np_\\theta\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)=N\\left(g\\left(\\mathbf{z}_t\\right),\\sigma_t^2I\\right)\n$$\nAnd we have from other computations that:\n$$\nq\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t,\\mathbf{x}\\right)=\nN_{\\mathbf{z}_{t-1}}\\left(\\frac{\\left(1-\\alpha_{t-1}\\right)}{1-\\alpha_t}\\sqrt{1-\\beta_t}\\ \\mathbf{z}_t+\\frac{\\sqrt{\\alpha_{t-1}}\\beta_t}{1-\\alpha_t}\\mathbf{x},\\frac{\\beta_t\\left(1-\\alpha_{t-1}\\right)}{1-\\alpha_t}I\\right)\n$$\nThus, since we are computing the KL between two Gaussian distributions, we can actually compute the KL divergence here in closed form:\n$$\nD_{KL}\\left(q\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right) ||\\ p_\\theta\\left(\\mathbf{z}_{T-1}| \\mathbf{z}_T\\right)\\right)=\n\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\frac{\\left(1-\\alpha_{t-1}\\right)}{1-\\alpha_t}\\sqrt{1-\\beta_t}\\ \\mathbf{z}_t+\\frac{\\sqrt{\\alpha_{t-1}}\\beta_t}{1-\\alpha_t}\\mathbf{x}- \\mathbf{f}_\\theta\\left(\\mathbf{z}_t\\right)\\right|\\right|^2+C\n$$\nWhich is proportional to the squared difference between the means.\n\n### First Term:\n$$\nE_{\\mathbf{z}_1\\sim q\\left(\\mathbf{z}_1| \\mathbf{x}\\right)}\\left[\\log p_\\theta(\\mathbf{x}| \\mathbf{z}_1)\\right]=E_{\\mathbf{z}_1\\sim q\\left(\\mathbf{z}_1| \\mathbf{x}\\right)}\\left[-\\frac{\\left(\\mathbf{x}- \\mathbf{f}_\\theta\\left(\\mathbf{z}_1\\right)\\right)^2}{2\\sigma}_1^2\\right]\n$$\n### Back to Main Expression\n$$\n= E_{\\mathbf{z}_1\\sim q\\left(\\mathbf{z}_1| \\mathbf{x}\\right)}\\left[\\log p_\\theta(\\mathbf{x}| \\mathbf{z}_1)\\right]-\\sum_{t=2}^{t=T}{E_{\\mathbf{z}_t\\sim q\\left(\\mathbf{z}_t| \\mathbf{x}\\right)}\\left[D_{KL}\\left(q\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right) ||\\ \\ p_\\theta\\left(\\mathbf{z}_{t-1}| \\mathbf{z}_t\\right)\\right)\\ \\right]}\n$$\n$$\n=E_{\\mathbf{z}_1\\sim q\\left(\\mathbf{z}_1| \\mathbf{x}\\right)}\\left[-\\frac{\\left(\\mathbf{x}- \\mathbf{f}_\\theta\\left(\\mathbf{z}_1\\right)\\right)^2}{{2\\sigma}_1^2}\\right]-\\ \\sum_{t=2}^{t=T}{E_{\\mathbf{z}_t\\sim q\\left(\\mathbf{z}_t| \\mathbf{x}\\right)}\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\frac{\\left(1-\\alpha_{t-1}\\right)}{1-\\alpha_t}\\sqrt{1-\\beta_t}\\ \\mathbf{z}_t+\\frac{\\sqrt{\\alpha_{t-1}}\\beta_t}{1-\\alpha_t}\\mathbf{x}- \\mathbf{f}_\\theta\\left(\\mathbf{z}_t\\right)\\right|\\right|^2}\n$$\nMaximizing this means minimizing this:\n$$\n=E_{\\mathbf{z}_1\\sim q\\left(\\mathbf{z}_1| \\mathbf{x}\\right)}\\left[\\frac{\\left(\\mathbf{x}- \\mathbf{f}_\\theta\\left(\\mathbf{z}_1\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\ \\sum_{t=2}^{t=T}{E_{\\mathbf{z}_t\\sim q\\left(\\mathbf{z}_t| \\mathbf{x}\\right)}\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\frac{\\left(1-\\alpha_{t-1}\\right)}{1-\\alpha_t}\\sqrt{1-\\beta_t}\\ \\mathbf{z}_t+\\frac{\\sqrt{\\alpha_{t-1}}\\beta_t}{1-\\alpha_t}\\mathbf{x}- \\mathbf{f}_\\theta\\left(\\mathbf{z}_t\\right)\\right|\\right|^2}\n$$\nWe can imagine minimizing this term regarding a specific $\\mathbf{x}$ by sampling $\\mathbf{z}_1,\\ldots,\\mathbf{z}_{T}$ from $\\mathbf{x}$, computing the expression, and changing the parameters of $\\mathbf{f}$. We can see this more clearly by adding stuff to the expectations.\n$$\n=E_{\\mathbf{z}_{1,\\ldots,T}\\sim q\\left(\\mathbf{z}_{1,\\ldots,T}| \\mathbf{x}\\right)}\\left[\\frac{\\left(\\mathbf{x}- \\mathbf{f}_\\theta\\left(\\mathbf{z}_1\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\ \\sum_{t=2}^{t=T}{E_{\\mathbf{z}_{1,\\ldots,T}\\sim q\\left(\\mathbf{z}_{1,\\ldots,T}| \\mathbf{x}\\right)}\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\frac{\\left(1-\\alpha_{t-1}\\right)}{1-\\alpha_t}\\sqrt{1-\\beta_t}\\ \\mathbf{z}_t+\\frac{\\sqrt{\\alpha_{t-1}}\\beta_t}{1-\\alpha_t}\\mathbf{x}- \\mathbf{f}_\\theta\\left(\\mathbf{z}_t\\right)\\right|\\right|^2}\n$$\n$$\n=E_{\\mathbf{z}_{1,\\ldots,T}\\sim q\\left(\\mathbf{z}_{1,\\ldots,T}| \\mathbf{x}\\right)}\\left[\\frac{\\left(\\mathbf{x}- \\mathbf{f}_\\theta\\left(\\mathbf{z}_1\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\ E_{\\mathbf{z}_{1,\\ldots,T}\\sim q\\left(\\mathbf{z}_{1,\\ldots,T}| \\mathbf{x}\\right)}\\left[\\sum_{t=2}^{t=T}{\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\frac{\\left(1-\\alpha_{t-1}\\right)}{1-\\alpha_t}\\sqrt{1-\\beta_t}\\ \\mathbf{z}_t+\\frac{\\sqrt{\\alpha_{t-1}}\\beta_t}{1-\\alpha_t}\\mathbf{x}- \\mathbf{f}_\\theta\\left(\\mathbf{z}_t\\right)\\right|\\right|^2}\\right]\n$$\n$$\n=\\ E_{\\mathbf{z}_{1,\\ldots,T}\\sim q\\left(\\mathbf{z}_{1,\\ldots,T}| \\mathbf{x}\\right)}\\left[\\frac{\\left(\\mathbf{x}- \\mathbf{f}_\\theta\\left(\\mathbf{z}_1\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\frac{\\left(1-\\alpha_{t-1}\\right)}{1-\\alpha_t}\\sqrt{1-\\beta_t}\\ \\mathbf{z}_t+\\frac{\\sqrt{\\alpha_{t-1}}\\beta_t}{1-\\alpha_t}\\mathbf{x}- \\mathbf{f}_\\theta\\left(\\mathbf{z}_t\\right)\\right|\\right|^2}\n$$\nNow using a Monte Carlo estimate:\n$$\n=\\ \\sum_{i=1}^{N}\\left[\\frac{\\left(\\mathbf{x}^{\\left(i\\right)}- \\mathbf{f}_\\theta\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right)^2}{{2\\sigma}_1^2}+\\sum_{t=2}^{t=T}{\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\frac{\\left(1-\\alpha_{t-1}\\right)}{1-\\alpha_t}\\sqrt{1-\\beta_t}\\ \\mathbf{z}_t^{\\left(i\\right)}+\\frac{\\sqrt{\\alpha_{t-1}}\\beta_t}{1-\\alpha_t}\\mathbf{x}- \\mathbf{f}_\\theta\\left(\\mathbf{z}_t^{\\left(i\\right)}\\right)\\right|\\right|^2}\\right]\n$$\nThe loss function minimizes the difference between the estimated mean $\\mathbf{f}(\\mathbf{z}_t)$ of $\\mathbf{z}_{t-1}$, and the most likely value (mean) it took, given $\\mathbf{z}_t$ and $\\mathbf{x}$.\n{% endraw %}"}, {"color": {"background": "#c876a3", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/chapters/DDPM-Reparametrization/", "id": "DDPM - Reparametrization", "label": "\u201cDDPM - Reparametrization\u201d", "mass": 1.0, "shape": "dot", "size": 10.0, "title": "# DDPM - Reparametrization\n{% raw %}\n\n### Expressing $\\mathbf{z}_t$ in terms of noise\n\nNote that\n$$\n\\mathbf{z}_t=\\sqrt{\\alpha_t }\\ \\mathbf{x}+\\sqrt{1-\\alpha_t}\\ \\mathbf{\\epsilon}\n$$\nWe can rearrange to write $\\mathbf{x}$ as:\n$$\n\\mathbf{x}=\\frac{\\mathbf{z}_t}{\\sqrt{\\alpha_t}}-\\frac{\\sqrt{1-\\alpha_t}}{\\sqrt{\\alpha_t}}\\mathbf{\\epsilon}\n$$\nAnd we substitute this into our objective.\n\nFirst, we denote $\\mathbf{\\epsilon}_t^{(i)}$ as the noise added to data sample $i$ at time step $t$, to get $\\mathbf{z}_t$ (when we are using the diffusion kernel, which is going straight from $\\mathbf{x}$ to $\\mathbf{z}_t$)\n\n$$\n\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(\\frac{\\mathbf{z}_1^{\\left(i\\right)}}{\\sqrt{\\alpha_1}}-\\frac{\\sqrt{1-\\alpha_1}}{\\sqrt{\\alpha_1}}\\mathbf{\\epsilon}_1^{(i)}-f\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\frac{\\left(1-\\alpha_{t-1}\\right)}{1-\\alpha_t}\\sqrt{1-\\beta_t}\\ \\mathbf{z}_t^{\\left(i\\right)}+\\frac{\\sqrt{\\alpha_{t-1}}\\beta_t}{1-\\alpha_t}\\left(\\frac{\\mathbf{z}_t^{(i)}}{\\sqrt{\\alpha_t}}-\\frac{\\sqrt{1-\\alpha_t}\\mathbf{\\epsilon}_t^{(i)}}{\\sqrt{\\alpha_t}}\\right)-f\\left(\\mathbf{z}_t^{\\left(i\\right)}\\right)\\right|\\right|^2}\\right]\n$$\n$$\n\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(\\frac{1}{\\sqrt{\\alpha_1}}\\mathbf{z}_1^{\\left(i\\right)}-\\frac{\\sqrt{1-\\alpha_1}}{\\sqrt{\\alpha_1}}\\mathbf{\\epsilon}_1^{(i)}-f\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\frac{1}{(1-\\alpha_t)}\\left(\\left(1-\\alpha_{t-1}\\right){\\sqrt{1-\\beta_t}}_\\ +\\frac{\\sqrt{\\alpha_{t-1}}\\beta_t}{\\sqrt{\\alpha_t}}\\ \\right)\\mathbf{z}_t^{\\left(i\\right)}-\\frac{\\sqrt{\\alpha_{t-1}}\\beta_t\\sqrt{1-\\alpha_t}}{(1-\\alpha_t)\\sqrt{\\alpha_t}}\\mathbf{\\epsilon}_t^{(i)}-f\\left(\\mathbf{z}_t^{\\left(i\\right)}\\right)\\right|\\right|^2}\\right]\n$$\nNote that:\n$\\alpha_t=\\alpha_{t-1}\\left(1-\\beta_t\\right)$, so $\\frac{\\alpha_{t-1}}{\\alpha_t}=\\frac{1}{(1-\\beta_t)}$\n$$\n=\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(\\frac{1}{\\sqrt{\\alpha_1}}\\mathbf{z}_1^{\\left(i\\right)}-\\frac{\\sqrt{1-\\alpha_1}}{\\sqrt{\\alpha_1}}\\mathbf{\\epsilon}_1^{(i)}-f\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\frac{1}{(1-\\alpha_t)}\\left(\\left(1-\\alpha_{t-1}\\right){\\sqrt{1-\\beta_t}}_\\ +\\frac{\\beta_t}{\\sqrt{1-\\beta_t}}\\ \\right)\\mathbf{z}_t^{\\left(i\\right)}-\\frac{\\beta_t}{\\sqrt{1-\\alpha_t}\\sqrt{1-\\beta_t}}\\mathbf{\\epsilon}_t^{(i)}-f\\left(\\mathbf{z}_t^{\\left(i\\right)}\\right)\\right|\\right|^2}\\right]\n$$\n$$=\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(\\frac{1}{\\sqrt{\\alpha_1}}\\mathbf{z}_1^{\\left(i\\right)}-\\frac{\\sqrt{1-\\alpha_1}}{\\sqrt{\\alpha_1}}\\mathbf{\\epsilon}_1^{(i)}-f\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\left(\\frac{\\left(1-\\alpha_{t-1}\\right)}{(1-\\alpha_t)}{\\sqrt{1-\\beta_t}}_\\ +\\frac{\\beta_t}{(1-\\alpha_t)\\sqrt{1-\\beta_t}}\\ \\right)\\mathbf{z}_t^{\\left(i\\right)}-\\frac{\\beta_t}{\\sqrt{1-\\alpha_t}\\sqrt{1-\\beta_t}}\\mathbf{\\epsilon}_t^{(i)}-f\\left(\\mathbf{z}_t^{\\left(i\\right)}\\right)\\right|\\right|^2}\\right]\n$$\n$$\n=\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(\\frac{1}{\\sqrt{\\alpha_1}}\\mathbf{z}_1^{\\left(i\\right)}-\\frac{\\sqrt{1-\\alpha_1}}{\\sqrt{\\alpha_1}}\\mathbf{\\epsilon}_1^{(i)}-f\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\left(\\frac{\\left(1-\\alpha_{t-1}\\right)\\sqrt{1-\\beta_t}}{(1-\\alpha_t)\\sqrt{1-\\beta_t}}{\\sqrt{1-\\beta_t}}_\\ +\\frac{\\beta_t}{(1-\\alpha_t)\\sqrt{1-\\beta_t}}\\ \\right)\\mathbf{z}_t^{\\left(i\\right)}-\\frac{\\beta_t}{\\sqrt{1-\\alpha_t}\\sqrt{1-\\beta_t}}\\mathbf{\\epsilon}_t^{(i)}-f\\left(\\mathbf{z}_t^{\\left(i\\right)}\\right)\\right|\\right|^2}\\right]\n$$\n$$\n=\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(\\frac{1}{\\sqrt{\\alpha_1}}\\mathbf{z}_1^{\\left(i\\right)}-\\frac{\\sqrt{1-\\alpha_1}}{\\sqrt{\\alpha_1}}\\mathbf{\\epsilon}_1^{(i)}-f\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\left(\\frac{\\left(1-\\alpha_{t-1}\\right)(1-\\beta_t)}{(1-\\alpha_t)\\sqrt{1-\\beta_t}}+\\frac{\\beta_t}{(1-\\alpha_t)\\sqrt{1-\\beta_t}}\\ \\right)\\mathbf{z}_t^{\\left(i\\right)}-\\frac{\\beta_t}{\\sqrt{1-\\alpha_t}\\sqrt{1-\\beta_t}}\\mathbf{\\epsilon}_t^{(i)}-f\\left(\\mathbf{z}_t^{\\left(i\\right)}\\right)\\right|\\right|^2}\\right]\n$$\n$$\n=\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(\\frac{1}{\\sqrt{\\alpha_1}}\\mathbf{z}_1^{\\left(i\\right)}-\\frac{\\sqrt{1-\\alpha_1}}{\\sqrt{\\alpha_1}}\\mathbf{\\epsilon}_1^{(i)}-f\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\left(\\frac{\\left(1-\\alpha_{t-1}\\right)\\left(1-\\beta_t\\right)+\\beta_t}{(1-\\alpha_t)\\sqrt{1-\\beta_t}}\\ \\right)\\mathbf{z}_t^{\\left(i\\right)}-\\frac{\\beta_t}{\\sqrt{1-\\alpha_t}\\sqrt{1-\\beta_t}}\\mathbf{\\epsilon}_t^{(i)}-f\\left(\\mathbf{z}_t^{\\left(i\\right)}\\right)\\right|\\right|^2}\\right]\n$$\n$$\n=\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(\\frac{1}{\\sqrt{\\alpha_1}}\\mathbf{z}_1^{\\left(i\\right)}-\\frac{\\sqrt{1-\\alpha_1}}{\\sqrt{\\alpha_1}}\\mathbf{\\epsilon}_1^{(i)}-f\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\left(\\frac{\\left(1-\\alpha_{t-1}+\\alpha_{t-1}\\beta_t\\right)}{(1-\\alpha_t)\\sqrt{1-\\beta_t}}\\ \\right)\\mathbf{z}_t^{\\left(i\\right)}-\\frac{\\beta_t}{\\sqrt{1-\\alpha_t}\\sqrt{1-\\beta_t}}\\mathbf{\\epsilon}_t^{(i)}-f\\left(\\mathbf{z}_t^{\\left(i\\right)}\\right)\\right|\\right|^2}\\right]\n$$\n$$\n=\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(\\frac{1}{\\sqrt{\\alpha_1}}\\mathbf{z}_1^{\\left(i\\right)}-\\frac{\\sqrt{1-\\alpha_1}}{\\sqrt{\\alpha_1}}\\mathbf{\\epsilon}_1^{(i)}-f\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\left(\\frac{\\left(1-\\alpha_{t-1}(1-\\beta_t\\right)}{(1-\\alpha_t)\\sqrt{1-\\beta_t}}\\ \\right)\\mathbf{z}_t^{\\left(i\\right)}-\\frac{\\beta_t}{\\sqrt{1-\\alpha_t}\\sqrt{1-\\beta_t}}\\mathbf{\\epsilon}_t^{(i)}-f\\left(\\mathbf{z}_t^{\\left(i\\right)}\\right)\\right|\\right|^2}\\right]\n$$\n$$\n=\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(\\frac{1}{\\sqrt{\\alpha_1}}\\mathbf{z}_1^{\\left(i\\right)}-\\frac{\\sqrt{1-\\alpha_1}}{\\sqrt{\\alpha_1}}\\mathbf{\\epsilon}_1^{(i)}-f\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\left(\\frac{\\left(1-\\alpha_t\\right)}{(1-\\alpha_t)\\sqrt{1-\\beta_t}}\\ \\right)\\mathbf{z}_t^{\\left(i\\right)}-\\frac{\\beta_t}{\\sqrt{1-\\alpha_t}\\sqrt{1-\\beta_t}}\\mathbf{\\epsilon}_t^{(i)}-f\\left(\\mathbf{z}_t^{\\left(i\\right)}\\right)\\right|\\right|^2}\\right]\n$$\n$$\n\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(\\frac{1}{\\sqrt{\\alpha_1}}\\mathbf{z}_1^{\\left(i\\right)}-\\frac{\\sqrt{1-\\alpha_1}}{\\sqrt{\\alpha_1}}\\mathbf{\\epsilon}_1^{(i)}-f\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\left(\\frac{1}{\\sqrt{1-\\beta_t}}\\ \\right)\\mathbf{z}_t^{\\left(i\\right)}-\\frac{\\beta_t}{\\sqrt{1-\\alpha_t}\\sqrt{1-\\beta_t}}\\mathbf{\\epsilon}_t^{(i)}-f\\left(\\mathbf{z}_t^{\\left(i\\right)}\\right)\\right|\\right|^2}\\right]\n$$\n$$\n\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(\\frac{1}{\\sqrt{1-\\beta_1}}\\mathbf{z}_1^{\\left(i\\right)}-\\frac{\\sqrt{{\\beta}_1}}{\\sqrt{1-{\\beta}_1}}\\mathbf{\\epsilon}_1^{(i)}-f\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\left(\\frac{1}{\\sqrt{1-\\beta_t}}\\ \\right)\\mathbf{z}_t^{\\left(i\\right)}-\\frac{\\beta_t}{\\sqrt{1-\\alpha_t}\\sqrt{1-\\beta_t}}\\mathbf{\\epsilon}_t^{(i)}-f\\left(\\mathbf{z}_t^{\\left(i\\right)}\\right)\\right|\\right|^2}\\right]\n$$\nObserve that if we multiply the numerator and denominator by $\\sqrt{\\beta_1}$ in coefficient on $\\mathbf{\\epsilon}_1$, the form of the first half of the sum matches the second half.\n\n### Defining $\\mathbf{g}$, our neural network\nNow $\\mathbf{f}$, is our model, so we parametrize it however we want. It\u00e2\u20ac\u2122s just a formula we use with some parameters, with $\\mathbf{z}_t^{(i)}$ as input. So, let \n$$\n\\mathbf{f}\\left(\\mathbf{z}_t^{\\left(i\\right)}\\right)=\\ \\left(\\frac{1}{\\sqrt{1-\\beta_t}}\\ \\right)\\mathbf{z}_t^{\\left(i\\right)}-\\frac{\\beta_t}{\\sqrt{1-\\alpha_t}\\sqrt{1-\\beta_t}}g(\\mathbf{z}_t^{\\left(i\\right)})\n$$\nWhich we are totally allowed to do, since it\u00e2\u20ac\u2122s just another function of $\\mathbf{z}_t^{(i)}$.\nThen we get\n$$\n\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(\\frac{1}{\\sqrt{1-\\beta_1}}\\mathbf{z}_1^{\\left(i\\right)}-\\frac{\\sqrt{{\\beta}_1}}{\\sqrt{1-{\\beta}_1}}\\mathbf{\\epsilon}-f\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|\\left(\\frac{1}{\\sqrt{1-\\beta_t}}\\ \\right)\\mathbf{z}_t^{\\left(i\\right)}-\\frac{\\beta_t}{\\sqrt{1-\\alpha_t}\\sqrt{1-\\beta_t}}\\mathbf{\\epsilon}_t^{(i)}-\\ \\left(\\frac{1}{\\sqrt{1-\\beta_t}}\\ \\right)\\mathbf{z}_t^{\\left(i\\right)}+\\frac{\\beta_t}{\\sqrt{1-\\alpha_t}\\sqrt{1-\\beta_t}}g(\\mathbf{z}_t^{\\left(i\\right)})\\right|\\right|^2}\\right]\n$$\n$$\n\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(\\frac{1}{\\sqrt{1-\\beta_1}}\\mathbf{z}_1^{\\left(i\\right)}-\\frac{\\sqrt{{\\beta}_1}}{\\sqrt{1-{\\beta}_1}}\\mathbf{\\epsilon}-f\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|-\\frac{\\beta_t}{\\sqrt{1-\\alpha_t}\\sqrt{1-\\beta_t}}\\mathbf{\\epsilon}_t^{(i)}+\\frac{\\beta_t}{\\sqrt{1-\\alpha_t}\\sqrt{1-\\beta_t}}g(\\mathbf{z}_t^{\\left(i\\right)})\\right|\\right|^2}\\right]\n$$\n$$\n\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(\\frac{1}{\\sqrt{1-\\beta_1}}\\mathbf{z}_1^{\\left(i\\right)}-\\frac{\\sqrt{{\\beta}_1}}{\\sqrt{1-{\\beta}_1}}\\mathbf{\\epsilon}-f\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{1}{2\\sigma_t^2}\\ \\left|\\left|-\\frac{\\beta_t}{\\sqrt{1-\\alpha_t}\\sqrt{1-\\beta_t}}\\left(\\mathbf{\\epsilon}_t^{(i)}-g\\left(\\mathbf{z}_t^{\\left(i\\right)}\\right)\\right)\\right|\\right|^2}\\right]\n$$\n$$\n\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(\\frac{1}{\\sqrt{1-\\beta_1}}\\mathbf{z}_1^{\\left(i\\right)}-\\frac{\\sqrt{{\\beta}_1}}{\\sqrt{1-{\\beta}_1}}\\mathbf{\\epsilon}-f\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{\\beta_t^2}{2\\sigma_t^2(1-\\alpha_t)(1-\\beta_t)}\\ \\left|\\left|\\mathbf{\\epsilon}_t^{(i)}-g(\\mathbf{z}_t^{\\left(i\\right)})\\right|\\right|^2}\\right]\n$$\n$$\n\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(\\frac{1}{\\sqrt{1-\\beta_1}}\\mathbf{z}_1^{\\left(i\\right)}-\\frac{\\sqrt{{\\beta}_1}}{\\sqrt{1-{\\beta}_1}}\\mathbf{\\epsilon}-\\left(\\frac{1}{\\sqrt{1-\\beta_1}}\\ \\right)\\mathbf{z}_t^{\\left(i\\right)}+\\frac{\\beta_1}{\\sqrt{1-\\alpha_1}\\sqrt{1-\\beta_1}}g(\\mathbf{z}_1^{\\left(i\\right)})\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{\\beta_t^2}{2\\sigma_t^2(1-\\alpha_t)(1-\\beta_t)}\\ \\left|\\left|\\mathbf{\\epsilon}_t^{(i)}-g(\\mathbf{z}_t^{\\left(i\\right)})\\right|\\right|^2}\\right]\n$$\n$$\n\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(-\\frac{\\sqrt{{\\beta}_1}}{\\sqrt{1-{\\beta}_1}}\\mathbf{\\epsilon}+\\frac{\\beta_1}{\\sqrt{1-\\alpha_1}\\sqrt{1-\\beta_1}}g(\\mathbf{z}_1^{\\left(i\\right)})\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{\\beta_t^2}{2\\sigma_t^2(1-\\alpha_t)(1-\\beta_t)}\\ \\left|\\left|\\mathbf{\\epsilon}_t^{(i)}-g(\\mathbf{z}_t^{\\left(i\\right)})\\right|\\right|^2}\\right]\n\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(-\\frac{{\\beta}_1}{\\sqrt{{\\beta}_1}\\sqrt{1-{\\beta}_1}}\\mathbf{\\epsilon}+\\frac{\\beta_1}{\\sqrt{\\beta_1}\\sqrt{1-\\beta_1}}g(\\mathbf{z}_1^{\\left(i\\right)})\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{\\beta_t^2}{2\\sigma_t^2(1-\\alpha_t)(1-\\beta_t)}\\ \\left|\\left|\\mathbf{\\epsilon}_t^{(i)}-g(\\mathbf{z}_t^{\\left(i\\right)})\\right|\\right|^2}\\right]\n$$\n$$\n\\sum_{i=1}^{100}\\left[\\left[\\frac{\\left(-\\frac{{\\beta}_1}{\\sqrt{{\\beta}_1}\\sqrt{1-{\\beta}_1}}\\left[\\mathbf{\\epsilon}-g\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right]\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{\\beta_t^2}{2\\sigma_t^2(1-\\alpha_t)(1-\\beta_t)}\\ \\left|\\left|\\mathbf{\\epsilon}_t^{(i)}-g(\\mathbf{z}_t^{\\left(i\\right)})\\right|\\right|^2}\\right]\n$$\n$$\n\\sum_{i=1}^{100}\\left[\\left[\\frac{\\frac{{\\beta}_1^2}{{\\beta}_1(1-{\\beta}_1)}\\left(\\left[\\mathbf{\\epsilon}-g\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right]\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{\\beta_t^2}{2\\sigma_t^2(1-\\alpha_t)(1-\\beta_t)}\\ \\left|\\left|\\mathbf{\\epsilon}_t^{(i)}-g(\\mathbf{z}_t^{\\left(i\\right)})\\right|\\right|^2}\\right]\n$$\n$$\n\\sum_{i=1}^{100}\\left[\\left[\\frac{\\frac{{\\beta}_1^2}{(1-{\\alpha}_1)(1-{\\beta}_1)}\\left(\\left[\\mathbf{\\epsilon}-g\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right]\\right)^2}{{2\\sigma}_1^2}\\right]+\\sum_{t=2}^{t=T}{\\frac{\\beta_t^2}{2\\sigma_t^2(1-\\alpha_t)(1-\\beta_t)}\\ \\left|\\left|\\mathbf{\\epsilon}_t^{(i)}-g(\\mathbf{z}_t^{\\left(i\\right)})\\right|\\right|^2}\\right]\n$$\n$$\n\\sum_{i=1}^{100}\\left[\\left[\\frac{{\\beta}_1^2}{{2\\sigma}_1^2(1-{\\alpha}_1)(1-{\\beta}_1)}\\right]\\left(\\left[\\mathbf{\\epsilon}-g\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right]\\right)^2+\\sum_{t=2}^{t=T}{\\frac{\\beta_t^2}{2\\sigma_t^2(1-\\alpha_t)(1-\\beta_t)}\\ \\left|\\left|\\mathbf{\\epsilon}_t^{(i)}-g(\\mathbf{z}_t^{\\left(i\\right)})\\right|\\right|^2}\\right]\n$$\n$$\n=\\sum_{i=1}^{100}\\left[\\left[\\frac{{\\beta}_1^2}{{2\\sigma}_1^2(1-{\\alpha}_1)(1-{\\beta}_1)}\\right]\\left(\\left[\\mathbf{\\epsilon}-g\\left(\\mathbf{z}_1^{\\left(i\\right)}\\right)\\right]\\right)^2+\\sum_{t=2}^{t=T}{\\frac{\\beta_t^2}{2\\sigma_t^2(1-\\alpha_t)(1-\\beta_t)}\\ \\left|\\left|\\mathbf{\\epsilon}_t^{(i)}-g(\\mathbf{z}_t^{\\left(i\\right)})\\right|\\right|^2}\\right]\n$$\n$$\n=\\sum_{i=1}^{100}\\left[\\sum_{t=1}^{t=T}{\\frac{\\beta_t^2}{2\\sigma_t^2(1-\\alpha_t)(1-\\beta_t)}\\ \\left|\\left|\\mathbf{\\epsilon}_t^{(i)}-g(\\mathbf{z}_t^{\\left(i\\right)})\\right|\\right|^2}\\right]\n$$\nThis is our objective.\nWe ignore the constants out front and simply it further:\n$$\n\\sum_{i=1}^{100}\\left[\\sum_{t=1}^{t=T}{\\ \\left|\\left|\\mathbf{\\epsilon}_t^{(i)}-g(\\mathbf{z}_t^{\\left(i\\right)})\\right|\\right|^2}\\right]\n$$\nSo we are just predicting the (unscaled) noise added. Another way to write it:\n$$\n\\sum_{{i}=1}^{\\mathbf{100}}\\left[\\sum_{{t}=1}^{{t}={T}}{\\ \\left|\\left|{\\mathbf{\\epsilon}}_{t}^{({i})}-{g}({\\mathbf{\\mathbf{x}}}_{i}\\sqrt{{\\alpha}_{t}}+{\\mathbf{\\epsilon}}_{t}^{\\left({i}\\right)}\\sqrt{1-{\\alpha}_{t}})\\right|\\right|^2}\\right]\n$$\n\n### Thus, to train a diffusion model:\n- For all data:\n -  For all time steps:\n\t- Generating a sample according to the diffusion kernel\n\t- Try to predict epsilon (the noise added pre-normalization), using MSE loss.\n\nOr, stochastically:\n\n- For a batch of data:\n\t- Generate random time step $t$\n\t- Generate noise $\\mathbf{\\epsilon} \\sim \\mathcal{N}(0,I)$\n\t- Optimize  $\\left\\|\\mathbf{\\epsilon}-\\ \\mathbf{g}(\\mathbf{x}_i\\sqrt{\\alpha_t}+\\mathbf{\\epsilon}\\sqrt{1-\\alpha_t}) \\right\\|^2$\n\nFor inference:\n- Sample from $\\mathcal{N}(0,I)$ to get $\\mathbf{z}_T$\n- Compute f:\n $f\\left(\\mathbf{z}_t\\right)=\\ \\left(\\frac{1}{\\sqrt{1-\\beta_t}}\\ \\right)\\mathbf{z}_t-\\frac{\\beta_t}{\\sqrt{1-\\alpha_t}\\sqrt{1-\\beta_t}}g(\\mathbf{z}_t)$\n- Sample $\\mathbf{z}_{t-1}$ from\n\t\t$\\mathcal{N}\\left(f\\left(\\mathbf{z}_t\\right),\\ \\sigma_t\\right)$\n\tEventually, we compute $\\mathbf{f}(\\mathbf{z}_1)$, which is our data sample.\nSigmas here are predetermined.\n{% endraw %}"}, {"color": "#ffd900", "fixed": false, "font": {"color": "white"}, "id": "Understanding Diffusion Models: A Unified Perspective", "label": "\u201cUnderstanding Diffusion Models: A Unified Perspective\u201d", "mass": 4.0, "shape": "dot", "size": 20.0, "title": "Last Recall: 7/14/24"}, {"color": "#ffd900", "fixed": false, "font": {"color": "white"}, "id": "Score Based Generative Models", "label": "\u201cScore Based Generative Models\u201d", "mass": 2.25, "shape": "dot", "size": 15.0, "title": ""}, {"color": "#ffd900", "fixed": false, "font": {"color": "white"}, "id": "Generative Modeling Using SDEs", "label": "\u201cGenerative Modeling Using SDEs\u201d", "mass": 1.2500000000000002, "shape": "dot", "size": 11.180339887498949, "title": ""}, {"color": {"background": "#ee802c", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Wiener-Process/", "id": "Wiener Process", "label": "Wiener Process", "mass": 0.25, "shape": "dot", "size": 5.0, "title": "# Wiener Process\n\n{% raw %}\n\n## Standard Wiener Process\n\n\n### Intuition\nA Wiener process (also called Brownian motion) is a continuous time process that is like a random walk. \n\nImagine a discrete-time random process where you start at position $\\mathbf{x_{t=0}} = \\mathbf{0}$. Then, your position at time $t$ is determined by\n\n$$\n\\mathbf{x}_{t} = \\mathbf{x}_{t-\\Delta t} + \\mathcal{N}(0,\\Delta t I)\n$$\n\nOr equivalently,\n\n$$\n\\mathbf{x}_{t} = \\mathbf{x}_{t-\\Delta t} + \\sqrt{\\Delta t} \\cdot \\mathcal{N}(0,I)\n$$\n\nIn other words, every time step, you change your position by a vector sampled from $\\mathcal{N}(0,\\Delta t I)$, where $\\Delta t$ is how long each time step is.\n\nA Wiener process is the continuous limit of this as $\\Delta t \\rightarrow 0$.\n\n### Definition\nWe define a set of independent random variables, or a function mapping the time $t$ to a random variable. It satisfies the property that\n\n$$\nW_0 = \\mathbf{0}\n$$\n\nAnd \n\n$$\nW_{t_2} - W_{t_1} = \\mathcal{N}(0, (t_2 - t_1)I)\n$$\n\nNote that this restriction is only possible because the variance of the sum of two independent random variables is the sum of the two variances. In other words, since $W_{t_1} \\perp W_{t_2}$ for all $t_1 \\neq t_2 $, the variance accumulates linearly over time.\n\n\nAlso, under this formulation, we have\n\n$$\nW_{t} = \\mathcal{N}(0, tI)\n$$\n\n\n\nlinearly as $t$ increases.\n\nIn other words, at every time step, we take a infinitesimally small step in a random direction proportional to a vector sampled from the standard normal:\n\n$$\ndW \\sim \\mathcal{N}(0, I dt)\n$$\n\nLast Reviewed: 2/4/25\n{% endraw %}\n"}, {"color": "#3FFF57", "fixed": false, "font": {"color": "white"}, "id": "Audio", "label": "Audio", "mass": 0.98, "shape": "dot", "size": 9.899494936611665, "title": ""}, {"color": {"background": "#baee38", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/papers/DiffWave/", "id": "DiffWave", "label": "\u201cDiffWave\u201d", "mass": 0.49, "shape": "dot", "size": 7.0, "title": "# DiffWave\nLast Reviewed: 1/23/25"}, {"color": {"background": "#3fff57", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/papers/DAC/", "id": "DAC", "label": "\u201cDAC\u201d", "mass": 0.49, "shape": "dot", "size": 7.0, "title": "# DAC\nResidual blocks with dilations 1, 3, 9 slash kernel size 7, and depthwise 1x1\nThese are chained together.\n\nDownsampling blocks that double channel\n\nUpsampling blocks that halve channel\n\nSnake activations\n\nfeature matching loss, multiscale STFT discriminator, mel-reconstruction loss\n\nLast Reviewed: 1/17/25"}, {"color": "#79443B", "fixed": false, "font": {"color": "white"}, "id": "Vision", "label": "Vision", "mass": 0.98, "shape": "dot", "size": 9.899494936611665, "title": ""}, {"color": {"background": "#bb8c35", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/papers/VAR/", "id": "VAR", "label": "\u201cVAR\u201d", "mass": 0.49, "shape": "dot", "size": 7.0, "title": "# VAR\nWorks in VQ-VAE Latent Space\n\nEncoding:\nTake 64x64 latent, squash to 1x1, quantize.\nlookup, stretch to K x K, compute residual\nSquash residual to 4x4, quantize residual\nlookup, stretch to K x K, compute residual\n...\nvery similar to RVQ but with \u0027squashing\u0027\n\nAutoregressive \u0027next-scale\u0027 predictions,\npredict first scale, then all of next scale in parallel, etc.\n\nraster scan order bad - disrupts locality, makes infilling hard due to bidirectional correlation, inefficient.\n\nLast Reviewed: 1/17/25"}, {"color": {"background": "#79443b", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/papers/Gaussian-Splatting/", "id": "Gaussian Splatting", "label": "\u201cGaussian Splatting\u201d", "mass": 0.49, "shape": "dot", "size": 7.0, "title": "# Gaussian Splatting\nSuper Fast Rendering - realtime display rates at 1080p\nHigher quality than Mip-Nerf\nAvoids unnecessary computation in empty space\n\nNerf and voxel-based 3D representations require stochastic sampling for rendering - computationally expensive, result in noise\n\nuse sparse point clouds obtained from SFM - no need for MVS\n1-5 million gaussians per scene\n\nRendering:\n-respect visibility ordering\n-sorting\n-tile-based rasterization\n\n\nopacity-based rendering --- \n---the \u0027opacity\u0027 (light absorption) assigned to a point\ndepends on the distance from the previously sampled point, AND the density at the point\nbasically, you are assuming the \u0027point\u0027 is a block that absorbs light\n\nThese are continuous representations, (not voxels)\nworks with randomly initalized gaussians\ncan project gaussians to 2D and perform alpha blending\n\nParametrize each gaussian with:\n    opacity, anisotropic covariance, spherical harmonics\n    \nadaptive density control - add or remove gaussians during training\nLast Reviewed: 1/17/25\n"}, {"color": "#00FF00", "fixed": false, "font": {"color": "white"}, "id": "Language Modeling", "label": "Language Modeling", "mass": 1.0, "shape": "dot", "size": 10.0, "title": ""}, {"color": {"background": "#00ff00", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/classes/Language-Modeling-from-Scratch/", "id": "Language Modeling from Scratch", "label": "\u201cLanguage Modeling from Scratch\u201d", "mass": 1.0, "shape": "dot", "size": 10.0, "title": "Last Recall: 6/14/24\n# Language Modeling from Scratch\n\nBPE\nFew-Shot/Zero Shot Generalization\nScaling Laws - parameters, data, training time, result in linear log-log curves with loss\n\nLast Reviewed: 6/1/24\n"}, {"color": {"background": "#00ff00", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Transformers/", "id": "Transformers", "label": "Transformers", "mass": 1.0, "shape": "dot", "size": 10.0, "title": "Last Recall: 6/14/24\n# Transformers\n\nTransformer Basics\nRotary Embeddings (Review)\nLayerNorm, projecting latent onto hypersphere\nMQA, GQA\nSwiGLU\nPrenorm vs postnorm\nLast Reviewed: 6/1/24\n"}, {"color": "#0000ff", "fixed": false, "font": {"color": "white"}, "id": "Interpretability", "label": "Interpretability", "mass": 0.49, "shape": "dot", "size": 7.0, "title": ""}, {"color": {"background": "#0000ff", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/papers/Concept-Activation-Vectors/", "id": "Concept Activation Vectors", "label": "\u201cConcept Activation Vectors\u201d", "mass": 0.49, "shape": "dot", "size": 7.0, "title": "# Concept Activation Vectors\nSpecify a concept by collecting examples\ntrain a classifier on these examples wrt random examples or another group (e.g. stripes vs dots)\ntake the orthogonal vector to this classifier (CAV)\ncompute the directional derivative of a class label (e.g. zebra) wrt CAV\ncan use to tell which concepts inform classifier decision\nother use cases (see notes)\n\nLast Reviewed: 10/27/24\nReference # 1"}, {"color": {"background": "#0000ff", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Fine-Tuning/", "id": "Fine Tuning", "label": "Fine Tuning", "mass": 0.0, "shape": "dot", "size": 5, "title": "# Fine Tuning\nLoRA\nControlNet\nSEGA\nLast Reviewed: 10/26/24\n"}, {"color": "#a8326f", "fixed": false, "font": {"color": "white"}, "id": "Signal Processing", "label": "Signal Processing", "mass": 2.45, "shape": "dot", "size": 15.652475842498529, "title": ""}, {"color": "#8a16b5", "fixed": false, "font": {"color": "white"}, "id": "DDSP", "label": "DDSP", "mass": 0.49, "shape": "dot", "size": 7.0, "title": ""}, {"color": {"background": "#a8326f", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/PQMF/", "id": "PQMF", "label": "PQMF", "mass": 0.49, "shape": "dot", "size": 7.0, "title": "# PQMF\n\nFilter signal into low band and high band\nDownsample both\nupsample both\nlow pass low band, high pass subband\nin the downsampled signal, the high frequencies are mirrored, and occupy the low frequencies.\nSpecial case of audio CNNs\nSee PQMF.ipynb\nLast Reviewed: 1/2/2024\n"}, {"color": {"background": "#a8326f", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Downsampling-and-Stretching/", "id": "Downsampling and Stretching", "label": "Downsampling and Stretching", "mass": 0.49, "shape": "dot", "size": 7.0, "title": "# Downsampling and Stretching\nLast Reviewed: 1/2/2025\n\nDownsampling \u0027folds\u0027 the FFT spectrum on itself.\ne.g. downsampling by factor of 2 - imagine slicing spec. in half,\nthen overlaying them.\n\nStretching replicates the FFT spectrum (doubles length of FFT)\nstretching by x2 mirrors spectrum,\nstretching by x3 appends the forward spectrum again\netc."}, {"color": {"background": "#a8326f", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Convolution/", "id": "Convolution", "label": "Convolution", "mass": 0.49, "shape": "dot", "size": 7.0, "title": "# Convolution\n\nConvolution in Neural Networks:\nDilated Convolution = replicating spectrum of filter\ndilated kernel size = (kernel_size - 1) * dilation + 1\nleads to higher frequency resolution (number of unique points)\nstrided convolution = conv plus downsampling\n\nnote that before downsampling, trailing entries are discarded.\n# of trailing entires discarded = stride - 1\ntherefore, the target size after conv only needs to be size - (stride - 1).\nTherefore, the input size after padding needs to be size - (stride - 1) + (kernel - 1), since the kernel takes away kernel - 1 units\nThis is equal to size + kernel - stride, so the padding needs to be (kernel - stride)/2.\nif stride is even, we therefore want an even kernel.\n\n\nGraph:\n   X X X X X X X X    - input\n[] X X X X X X X X [] - input after padding\n    X X X X X X X     - after conv, kernel size 4\n    X   X   X   X     - after downsampling\n\nOtherwise:\nTwo interpretations:\n1---reverb (overlapping kernels)\n2---flipping and shifting\nthe \u0027flipped\u0027 kernel is a function. The x is the \u0027offset\u0027 and the y is the \u0027weight\u0027.\ni.e., how does input at time t + x affect output at time t.\n\nLast Reviewed: 1/3/25"}, {"color": {"background": "#a8326f", "border": "white", "borderWidth": 1}, "fixed": false, "font": {"color": "white"}, "href": "https://maswang32.github.io/knowledgemap/notes/concepts/Transpose-Convolution/", "id": "Transpose Convolution", "label": "Transpose Convolution", "mass": 0.49, "shape": "dot", "size": 7.0, "title": "# Transpose Convolution\n\nWhen stride = 1, it\u0027s overlaying kernels\nThis is the \u0027superposition\u0027 interpretation of convolution\nit is the same as convolution with a flipped kernels\n\nWhen stride \u003e 1, it\u0027s the same as conv(stretch(x))\n\nSee the notebook you emailed Julius\n\nFilter the \u0027mirrored\u0027 copy of the signal\n\nGradient of Conv (makes forward and backwards same, natural way of upsampling)\n\nthe padding parameter is the same as truncating on both sides\nLast Reviewed: 1/3/25\n"}, {"color": "#808080", "fixed": false, "font": {"color": "white"}, "id": "Reinforcement Learning", "label": "Reinforcement Learning", "mass": 1.4899999999999998, "shape": "dot", "size": 12.206555615733702, "title": ""}, {"color": "#808080", "fixed": false, "font": {"color": "white"}, "id": "ReaLChords", "label": "\u201cReaLChords\u201d", "mass": 0.49, "shape": "dot", "size": 7.0, "title": "Last Recall: 9/25/24"}, {"color": "#808080", "fixed": false, "font": {"color": "white"}, "id": "CS 285", "label": "\u201cCS 285\u201d", "mass": 1.0, "shape": "dot", "size": 10.0, "title": "Last Recall: 9/25/24"}]);
                  edges = new vis.DataSet([{"arrows": "to", "color": "#C41E3A", "from": "Statistics", "to": "Math", "width": 4}, {"arrows": "to", "color": "#C41E3A", "from": "Information Theory", "to": "Math", "width": 4}, {"arrows": "to", "color": "#C41E3A", "from": "Linear Algebra", "to": "Math", "width": 4}, {"arrows": "to", "color": "#C41E3A", "from": "Calculus", "to": "Math", "width": 4}, {"arrows": "to", "color": "#FF6F20", "from": "Optimization", "to": "Statistics", "width": 4}, {"arrows": "to", "color": "#ff6f20", "from": "Momentum, RMSProp, Adam", "to": "Optimization", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "Gradients", "to": "Calculus", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "Gradients", "to": "Linear Algebra", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "Chain Rule", "to": "Gradients", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "Infinitesimals", "to": "Calculus", "width": 4}, {"arrows": "to", "color": "#C41E3A", "from": "Functions", "to": "Math", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "A Brief Introduction To Information", "to": "Information Theory", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "Deep Learning Chapter 3", "to": "Information Theory", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "KL Divergence", "to": "Information Theory", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "Six Interpretations of KL Divergence", "to": "KL Divergence", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "Entropy", "to": "Deep Learning Chapter 3", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "Cross Entropy", "to": "Deep Learning Chapter 3", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "Info Theory Basics", "to": "Deep Learning Chapter 3", "width": 4}, {"arrows": "to", "color": "#FF6F20", "from": "Random-Variables-and-Probability-Distributions", "to": "Statistics", "width": 4}, {"arrows": "to", "color": "#FF6F20", "from": "Bayes", "to": "Statistics", "width": 4}, {"arrows": "to", "color": "#FF6F20", "from": "Conditional Independence", "to": "Statistics", "width": 4}, {"arrows": "to", "color": "#212129", "from": "PyTorch", "to": "Software", "width": 4}, {"arrows": "to", "color": "#0000FF", "from": "PyTorch", "to": "Deep Learning", "width": 4}, {"arrows": "to", "color": "#0000FF", "from": "Activation Functions", "to": "Deep Learning", "width": 4}, {"arrows": "to", "color": "#0000ff", "from": "Pocketed Activations", "to": "Activation Functions", "width": 4}, {"arrows": "to", "color": "#0000ff", "from": "Gated Activations", "to": "Activation Functions", "width": 4}, {"arrows": "to", "color": "#0000FF", "from": "Understanding Deep Learning", "to": "Deep Learning", "width": 4}, {"arrows": "to", "color": "#0000ff", "from": "MLP Interpretation - UDL", "to": "Understanding Deep Learning", "width": 4}, {"arrows": "to", "color": "#0000ff", "from": "Loss Functions - UDL", "to": "Understanding Deep Learning", "width": 4}, {"arrows": "to", "color": "#0000FF", "from": "Generative Modeling", "to": "Deep Learning", "width": 4}, {"arrows": "to", "color": "#0000ff", "from": "VAEs - UDL", "to": "Understanding Deep Learning", "width": 4}, {"arrows": "to", "color": "#FFD900", "from": "VAEs - UDL", "to": "Generative Modeling", "width": 4}, {"arrows": "to", "color": "#ff6f20", "from": "ELBO", "to": "Optimization", "width": 4}, {"arrows": "to", "color": "#c876a3", "from": "ELBO", "to": "VAEs - UDL", "width": 4}, {"arrows": "to", "color": "#e87267", "from": "Jensens Inequality", "to": "ELBO", "width": 4}, {"arrows": "to", "color": "#0000ff", "from": "Optimization - UDL", "to": "Understanding Deep Learning", "width": 4}, {"arrows": "to", "color": "#ff6f20", "from": "Optimization - UDL", "to": "Optimization", "width": 4}, {"arrows": "to", "color": "#FFD900", "from": "Diffusion Models", "to": "Generative Modeling", "width": 4}, {"arrows": "to", "color": "#0000ff", "from": "DDPM - UDL", "to": "Understanding Deep Learning", "width": 4}, {"arrows": "to", "color": "#ffd900", "from": "DDPM - UDL", "to": "Diffusion Models", "width": 4}, {"arrows": "to", "color": "#c876a3", "from": "DDPM - Math", "to": "DDPM - UDL", "width": 4}, {"arrows": "to", "color": "#c876a3", "from": "DDPM - Reparametrization", "to": "DDPM - UDL", "width": 4}, {"arrows": "to", "color": "#ffd900", "from": "Understanding Diffusion Models: A Unified Perspective", "to": "Diffusion Models", "width": 4}, {"arrows": "to", "color": "#ffd900", "from": "Score Based Generative Models", "to": "Diffusion Models", "width": 4}, {"arrows": "to", "color": "#ffd900", "from": "Generative Modeling Using SDEs", "to": "Score Based Generative Models", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "Wiener Process", "to": "Calculus", "width": 4}, {"arrows": "to", "color": "#FF6F20", "from": "Wiener Process", "to": "Statistics", "width": 4}, {"arrows": "to", "color": "#ffd900", "from": "Wiener Process", "to": "Generative Modeling Using SDEs", "width": 4}, {"arrows": "to", "color": "#3FFF57", "from": "DiffWave", "to": "Audio", "width": 4}, {"arrows": "to", "color": "#ffd900", "from": "DiffWave", "to": "Diffusion Models", "width": 4}, {"arrows": "to", "color": "#3FFF57", "from": "DAC", "to": "Audio", "width": 4}, {"arrows": "to", "color": "#79443B", "from": "VAR", "to": "Vision", "width": 4}, {"arrows": "to", "color": "#FFD900", "from": "VAR", "to": "Generative Modeling", "width": 4}, {"arrows": "to", "color": "#79443B", "from": "Gaussian Splatting", "to": "Vision", "width": 4}, {"arrows": "to", "color": "#0000FF", "from": "Language Modeling", "to": "Deep Learning", "width": 4}, {"arrows": "to", "color": "#00FF00", "from": "Language Modeling from Scratch", "to": "Language Modeling", "width": 4}, {"arrows": "to", "color": "#00ff00", "from": "Transformers", "to": "Language Modeling from Scratch", "width": 4}, {"arrows": "to", "color": "#0000FF", "from": "Interpretability", "to": "Deep Learning", "width": 4}, {"arrows": "to", "color": "#0000ff", "from": "Concept Activation Vectors", "to": "Interpretability", "width": 4}, {"arrows": "to", "color": "#0000FF", "from": "Fine Tuning", "to": "Deep Learning", "width": 4}, {"arrows": "to", "color": "#a8326f", "from": "DDSP", "to": "Signal Processing", "width": 4}, {"arrows": "to", "color": "#0000FF", "from": "DDSP", "to": "Deep Learning", "width": 4}, {"arrows": "to", "color": "#a8326f", "from": "PQMF", "to": "Signal Processing", "width": 4}, {"arrows": "to", "color": "#a8326f", "from": "Downsampling and Stretching", "to": "Signal Processing", "width": 4}, {"arrows": "to", "color": "#a8326f", "from": "Convolution", "to": "Signal Processing", "width": 4}, {"arrows": "to", "color": "#a8326f", "from": "Transpose Convolution", "to": "Signal Processing", "width": 4}, {"arrows": "to", "color": "#808080", "from": "ReaLChords", "to": "Reinforcement Learning", "width": 4}, {"arrows": "to", "color": "#808080", "from": "CS 285", "to": "Reinforcement Learning", "width": 4}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {"nodes": {"borderWidth": 1, "borderWidthSelected": 3, "chosen": true, "shape": "dot", "font": {"size": 20, "color": "white"}}, "edges": {"color": {"inherit": true}, "smooth": false}, "physics": {"enabled": true, "solver": "hierarchicalRepulsion", "hierarchicalRepulsion": {"nodeDistance": 150, "centralGravity": 0.01, "springLength": 150, "springConstant": 0.001, "damping": 0.5}, "stabilization": {"enabled": true, "iterations": 2000, "fit": true}, "direction": "UD", "minVelocity": 0.75, "maxVelocity": 30}, "interaction": {"zoomView": true, "dragView": true, "zoomSpeed": 0.5, "mouseWheel": true}};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>