<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 100vh;
                 background-color: #000000;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             

             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"color": "#C41E3A", "fixed": false, "font": {"color": "white"}, "id": "Math", "label": "Math", "mass": 0.58, "shape": "dot", "size": 58, "title": ""}, {"color": "#c41e3a", "fixed": false, "font": {"color": "white"}, "id": "Statistics", "label": "Statistics", "mass": 0.2, "shape": "dot", "size": 20, "title": ""}, {"color": "#c41e3a", "fixed": false, "font": {"color": "white"}, "id": "Information Theory", "label": "Information Theory", "mass": 0.17, "shape": "dot", "size": 17, "title": ""}, {"color": "#c41e3a", "fixed": false, "font": {"color": "white"}, "id": "Linear Algebra", "label": "Linear Algebra", "mass": 0.2, "shape": "dot", "size": 20, "title": ""}, {"color": "#c41e3a", "fixed": false, "font": {"color": "white"}, "id": "Calculus", "label": "Calculus", "mass": 0.2, "shape": "dot", "size": 20, "title": ""}, {"color": "#c41e3a", "fixed": false, "font": {"color": "white"}, "id": "Optimization", "label": "Optimization", "mass": 0.2, "shape": "dot", "size": 20, "title": ""}, {"color": "#c41e3a", "fixed": false, "font": {"color": "white"}, "id": "Momentum, RMSProp, Adam", "label": "Momentum, RMSProp, Adam", "mass": 0.1, "shape": "dot", "size": 10, "title": "Last Recall: 11/9/24\n\nNotes from \"A visual explanation\"\n\nMomentum in Physics - F = ma, a force will cause a constant change in velocity.\nSame as momentum in ML - momentum = velocity, \nforces = decay (friction), and the additional gradient\nderivative = applying a force for one time frame, leading to an acceleration (change in velocity)\nmomentum helps with plateaus and local minima\n\n\nAdaGrad - history of squared gradients for a direction accumulate, updates in that direction are divided by this\nencourages exploration in directions where not many changes have happened\nescapes saddle points better - regular GD optimizes steeper features first\nslow b/c squared gradient accumuates\n\n\nRMSProp - squared gradients decay, squared gradients have momentum\n\nAdam - gradients have momentum, so do squared gradients.\nmomentum allows for escaping local minima\nsum of squares = explore new directions\n\n\n\nNotes from Andrew NG:\nMomentum cancels oscillations\nCorrections are usually applied to Adam so things get rolling earlier\n\n\n\n\n"}, {"color": "#c41e3a", "fixed": false, "font": {"color": "white"}, "id": "Gradients", "label": "Gradients", "mass": 0.2, "shape": "dot", "size": 20, "title": "Last Recall: 10/27/24\nGradient indicates direction of highest increase\nGradient specifies linearization (plane) of the function up to an offset (derivative gets rid of +C)\nGradient direction specifies plane orientation\nGradient magnitude specifies plane slope\nPlane tells you all directional derivatives"}, {"color": "#c41e3a", "fixed": false, "font": {"color": "white"}, "id": "Chain Rule", "label": "Chain Rule", "mass": 0.1, "shape": "dot", "size": 10, "title": "Last Recall: 10/27/24\nReference Page: #1\nUnivariate Chain Rule - \u0027speeding up\u0027 interperation.\n\u0027boosting\u0027 at a point\n\nAll derivatives are evaluated at the same point, just in different input domains\n\nMultivariate chain rule, dx,dy can be separated due to linearization.\nIncreases accumulate across dx, and dy.\n\nextending to multi-in, multi-out\nviewing things in terms of unit changes after linearization.\n\nKey Idea: we can think of moving dx in x, and then moving dy in y,\nand seeing how much f changes. This will be the same as moving in the directional derivative,\nsince for linear functions, the slope is the same everywhere.\n\nKey Idea: to compute df/ds, linearize everything, move one unit in s, and see how much that affects f.\n\nThe linearity assumption is the assumes that changes in variables will affect the output independently.\n\nwherever a function has a derivative, it is locally linear\n\n\nReference Page: #1"}, {"color": "#c41e3a", "fixed": false, "font": {"color": "white"}, "id": "Functions", "label": "Functions", "mass": 0.01, "shape": "dot", "size": 5, "title": "Last Recall: 12/1/24\n\npolynomials are a linear combination of x, x**2, x**3, as functions\n"}, {"color": "#c41e3a", "fixed": false, "font": {"color": "white"}, "id": "A Brief Introduction To Information", "label": "\u201cA Brief Introduction To Information\u201d", "mass": 0.02, "shape": "dot", "size": 5, "title": "Last Reviewed 11/9/2024\n\nAll information is communication - it requires a method of decoding, must be interpreted.\nAll digital info = bits\nSetup: communicate a sequence of random events\nstreaming setting requires prefix to disambiguate - I proved this\n"}, {"color": "#c41e3a", "fixed": false, "font": {"color": "white"}, "id": "Deep Learning Chapter 3", "label": "\u201cDeep Learning Chapter 3\u201d", "mass": 0.15, "shape": "dot", "size": 15, "title": ""}, {"color": "#c41e3a", "fixed": false, "font": {"color": "white"}, "id": "KL Divergence", "label": "KL Divergence", "mass": 0.05, "shape": "dot", "size": 5, "title": "Last Recall: 10/27/24\nAsymmetric\nDKL(P||Q) - symbols are drawn from P, but if we encode assuming drawn from Q, \nhow many extra bits on expectation are used\nEx~p[log(P(x))-log(Q(x))]\nAsymmetric b/c depends on which distribution you\u0027re sampling from - two examples\n(Should read more)\n\nhow much more suprised you\u0027d be seeing P while expecting Q\nReference Page: #2"}, {"color": "#c41e3a", "fixed": false, "font": {"color": "white"}, "id": "Entropy", "label": "Entropy", "mass": 0.05, "shape": "dot", "size": 5, "title": "Last Recall - 10/27/24\nExpected information in a distribution\nmeasures uncertainty in a probability distribution\nBernoulli Example\nReference Sheet #3."}, {"color": "#c41e3a", "fixed": false, "font": {"color": "white"}, "id": "Info Theory Basics", "label": "Info Theory Basics", "mass": 0.05, "shape": "dot", "size": 5, "title": "Last Recall - 10/27/24\nInformation is -logP(x) for an event\nIndependent events have additive infomration\nLess likely events have higher Information\nknowing outcome of an event with 50% prob has 1 bit of information\nMeasured in nats or bits (recall logs of all bases are proportional)\n0 information if certain\n\nsetup: a bitstream encodes a sequence of random vairables. Prefix requirements impose a cost of 2^l\n\nReference Sheet #3, 3.1"}, {"color": "#0000FF", "fixed": false, "font": {"color": "white"}, "id": "Deep Learning", "label": "Deep Learning", "mass": 0.74, "shape": "dot", "size": 74, "title": ""}, {"color": "#0000ff", "fixed": false, "font": {"color": "white"}, "id": "Understanding Deep Learning", "label": "\u201cUnderstanding Deep Learning\u201d", "mass": 0.3, "shape": "dot", "size": 30, "title": ""}, {"color": "#0000ff", "fixed": false, "font": {"color": "white"}, "id": "MLP Interpretation - UDL", "label": "\u201cMLP Interpretation - UDL\u201d", "mass": 0.1, "shape": "dot", "size": 10, "title": "Last Recall: 10/24/24\nShallow MLPs clip linear functions, rescale, and combine.\nD hidden units means D+1 Linear Regions\nMultivariate outputs are clipped at the same joints\nMultivariate Input Visualization\nAll ReLU MLPs split input space into Linear Regions\nFolding\nAdding a Layer is clipping Each Linear Region, and recombining\nBottlenecks are restricting weights to outer product\nDepth efficiency is exponential compared to width efficiency\nDepth generalizes and trains better\nSwishes solve Dying ReLU\nWeights can be rescaled as long as biases are too\nDepth approximation theorem"}, {"color": "#0000ff", "fixed": false, "font": {"color": "white"}, "id": "Loss Functions - UDL", "label": "\u201cLoss Functions - UDL\u201d", "mass": 0.1, "shape": "dot", "size": 10, "title": "Last Recall: 11/1/2024\nNegative Log Likelihood is a Loss\nFormula: Model predicts parameters of a distribution, on which the probability of data is evaluated.\nMaximize probability of data, minimize negative log probability of data.\nAssume data is conditionally independent\nMSE results from assuming y is sampled from gaussians with means determined by x\nheterodastic - variance varies with input\n\nBCE loss comes from assuming the distribution is Bernoulli (there\u0027s a visualization)\nmulticlass cross entropy loss \nTable of distributions from different taks\n\nin multi-output situations, assume different outputs are conditionally independent.\n\nNLL minimization is the same as minimizing cross entropy between data distributionsk\n\nReference Sheet: UDL Chapter 5\n"}, {"color": "#a4009a", "fixed": false, "font": {"color": "white"}, "id": "Optimization - UDL", "label": "\u201cOptimization - UDL\u201d", "mass": 0.1, "shape": "dot", "size": 10, "title": "Last Recall: 11/9/2024\n\n\n\n\nReference Sheet: UDL Chapter 6\n"}, {"color": "#0000ff", "fixed": false, "font": {"color": "white"}, "id": "Diffusion Models", "label": "Diffusion Models", "mass": 0.2, "shape": "dot", "size": 20, "title": ""}, {"color": {"background": "#0000ff", "border": "white"}, "fixed": false, "font": {"color": "white"}, "id": "Understanding Diffusion Models: A Unified Perspective", "label": "\u201cUnderstanding Diffusion Models: A Unified Perspective\u201d", "mass": 0.2, "shape": "dot", "size": 20, "title": "Last Recall: 7/14/24"}, {"color": "#00FF00", "fixed": false, "font": {"color": "white"}, "id": "Language Modeling", "label": "Language Modeling", "mass": 0.1, "shape": "dot", "size": 10, "title": ""}, {"color": "#00ff00", "fixed": false, "font": {"color": "white"}, "id": "Language Modeling from Scratch", "label": "\u201cLanguage Modeling from Scratch\u201d", "mass": 0.1, "shape": "dot", "size": 10, "title": "Last Recall: 6/14/24\nBPE\nFew-Shot/Zero Shot Generalization\nScaling Laws - parameters, data, training time, result in linear log-log curves with loss"}, {"color": "#00ff00", "fixed": false, "font": {"color": "white"}, "id": "Transformers", "label": "Transformers", "mass": 0.1, "shape": "dot", "size": 10, "title": "Last Recall: 6/14/24\nTransformer Basics\nRotary Embeddings (Review)\nLayerNorm, projecting latent onto hypersphere\nMQA, GQA\nSwiGLU\nPrenorm vs postnorm"}, {"color": "#0000ff", "fixed": false, "font": {"color": "white"}, "id": "Interpretability", "label": "Interpretability", "mass": 0.07, "shape": "dot", "size": 7, "title": ""}, {"color": "#0000ff", "fixed": false, "font": {"color": "white"}, "id": "Concept Activation Vectors", "label": "\u201cConcept Activation Vectors\u201d", "mass": 0.07, "shape": "dot", "size": 7, "title": "Last Recall: 10/27/24\nSpecify a concept by collecting examples\ntrain a classifier on these examples wrt random examples or another group (e.g. stripes vs dots)\ntake the orthogonal vector to this classifier (CAV)\ncompute the directional derivative of a class label (e.g. zebra) wrt CAV\ncan use to tell which concepts inform classifier decision\nother use cases (see notes)\nReference # 1"}, {"color": "#0000ff", "fixed": false, "font": {"color": "white"}, "id": "Fine Tuning", "label": "Fine Tuning", "mass": 0.0, "shape": "dot", "size": 5, "title": "Last Recall: 10/26/24\nLoRA\nControlNet\nSEGA"}, {"color": "#a8326f", "fixed": false, "font": {"color": "white"}, "id": "Signal Processing", "label": "Signal Processing", "mass": 0.07, "shape": "dot", "size": 7, "title": ""}, {"color": "#8a16b5", "fixed": false, "font": {"color": "white"}, "id": "DDSP", "label": "DDSP", "mass": 0.07, "shape": "dot", "size": 7, "title": ""}, {"color": "#808080", "fixed": false, "font": {"color": "white"}, "id": "Reinforcement Learning", "label": "Reinforcement Learning", "mass": 0.17, "shape": "dot", "size": 17, "title": ""}, {"color": "#808080", "fixed": false, "font": {"color": "white"}, "id": "ReaLChords", "label": "\u201cReaLChords\u201d", "mass": 0.07, "shape": "dot", "size": 7, "title": "Last Recall: 9/25/24"}, {"color": "#808080", "fixed": false, "font": {"color": "white"}, "id": "CS 285", "label": "\u201cCS 285\u201d", "mass": 0.1, "shape": "dot", "size": 10, "title": "Last Recall: 9/25/24"}]);
                  edges = new vis.DataSet([{"arrows": "to", "color": "#C41E3A", "from": "Statistics", "to": "Math", "width": 4}, {"arrows": "to", "color": "#C41E3A", "from": "Information Theory", "to": "Math", "width": 4}, {"arrows": "to", "color": "#C41E3A", "from": "Linear Algebra", "to": "Math", "width": 4}, {"arrows": "to", "color": "#C41E3A", "from": "Calculus", "to": "Math", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "Optimization", "to": "Statistics", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "Momentum, RMSProp, Adam", "to": "Optimization", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "Gradients", "to": "Linear Algebra", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "Gradients", "to": "Calculus", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "Chain Rule", "to": "Gradients", "width": 4}, {"arrows": "to", "color": "#C41E3A", "from": "Functions", "to": "Math", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "A Brief Introduction To Information", "to": "Information Theory", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "Deep Learning Chapter 3", "to": "Information Theory", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "KL Divergence", "to": "Deep Learning Chapter 3", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "Entropy", "to": "Deep Learning Chapter 3", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "Info Theory Basics", "to": "Deep Learning Chapter 3", "width": 4}, {"arrows": "to", "color": "#0000FF", "from": "Understanding Deep Learning", "to": "Deep Learning", "width": 4}, {"arrows": "to", "color": "#0000ff", "from": "MLP Interpretation - UDL", "to": "Understanding Deep Learning", "width": 4}, {"arrows": "to", "color": "#0000ff", "from": "Loss Functions - UDL", "to": "Understanding Deep Learning", "width": 4}, {"arrows": "to", "color": "#0000ff", "from": "Optimization - UDL", "to": "Understanding Deep Learning", "width": 4}, {"arrows": "to", "color": "#c41e3a", "from": "Optimization - UDL", "to": "Optimization", "width": 4}, {"arrows": "to", "color": "#0000FF", "from": "Diffusion Models", "to": "Deep Learning", "width": 4}, {"arrows": "to", "color": "#0000ff", "from": "Understanding Diffusion Models: A Unified Perspective", "to": "Diffusion Models", "width": 4}, {"arrows": "to", "color": "#0000FF", "from": "Language Modeling", "to": "Deep Learning", "width": 4}, {"arrows": "to", "color": "#00FF00", "from": "Language Modeling from Scratch", "to": "Language Modeling", "width": 4}, {"arrows": "to", "color": "#00ff00", "from": "Transformers", "to": "Language Modeling from Scratch", "width": 4}, {"arrows": "to", "color": "#0000FF", "from": "Interpretability", "to": "Deep Learning", "width": 4}, {"arrows": "to", "color": "#0000ff", "from": "Concept Activation Vectors", "to": "Interpretability", "width": 4}, {"arrows": "to", "color": "#0000FF", "from": "Fine Tuning", "to": "Deep Learning", "width": 4}, {"arrows": "to", "color": "#a8326f", "from": "DDSP", "to": "Signal Processing", "width": 4}, {"arrows": "to", "color": "#0000FF", "from": "DDSP", "to": "Deep Learning", "width": 4}, {"arrows": "to", "color": "#808080", "from": "ReaLChords", "to": "Reinforcement Learning", "width": 4}, {"arrows": "to", "color": "#808080", "from": "CS 285", "to": "Reinforcement Learning", "width": 4}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {"nodes": {"borderWidth": 2, "borderWidthSelected": 3, "chosen": true, "shape": "dot", "font": {"size": 20, "color": "white"}}, "edges": {"color": {"inherit": true}, "smooth": false}, "physics": {"enabled": true, "solver": "hierarchicalRepulsion", "hierarchicalRepulsion": {"nodeDistance": 150, "centralGravity": 0.01, "springLength": 150, "springConstant": 0.001, "damping": 0.5}, "stabilization": {"enabled": true, "iterations": 2000, "fit": true}, "direction": "UD", "minVelocity": 0.75, "maxVelocity": 30}, "interaction": {"zoomView": true, "dragView": true, "zoomSpeed": 0.5, "mouseWheel": true}};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>