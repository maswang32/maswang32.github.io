Last Reviewed: 1/23/25


Probabilisitic Interpretation.

p(z_{t-1} | z_t) is approximately normal, even for all timesteps.
This allows us to model a multimodal distirbution.
We sample from a normal distribution at each time-step, which can eventually allow us to be in a particular 'mode'.
You go down a specific path, basically, based on each sampling step.
Each sampling step kind of guides you down one path or another.


Even if the data distribution is very complex, going from step 100 to step 99 is approximately normal.

It is to hard to map N(0,1) to a data distribution with potentially many modes.
However, it is easier to do it one step at a time. sample z_100, and use that as the as the input to a network that calculates
the mean for z_99.

Eventually, you'll fall into one of the modes of the distribution.

It's like Plinko, but instead of each stick outputting 'left' or 'right' with 50/50 probability, the stick steers it in a certain direction.


also, fitting p(z_{t-1}, z_t) to q(z_{t-1}, z_t, x) will eventually give you 
a model for q(z_{t-1}, z_t), since we're taking the expectation over all data x, and fitting the same 
p to it.

Diffusion models try to learn p(z_{t-1}, z_t) by averaging over q(z_{t-1}, z_t, x) via monte-carlo sampling.






See math in "DiffusionMath"



https://sander.ai/2024/09/02/spectral-autoregression.html
https://sander.ai/2023/07/20/perspectives.html